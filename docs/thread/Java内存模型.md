Java Memory Model

java内存模型(JMM)屏蔽掉各种硬件和操作系统的内存访问差异，以实现让java程序在各种平台下都能达到一致的并发效果。

# 1. 为什么要有内存模型JMM？

要想回答这个问题，需要先弄懂传统计算机硬件内存架构。

## 1.1. 硬件内存架构

![传统计算机内存架构](https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204052048567.png)

（1）CPU

一般在大型服务器上会配置多个CPU，每个CPU还会有多个`核`，这就意味着多个CPU或者多个核可以同时（并发）工作。如果使用Java 起了一个多线程的任务，很有可能每个 CPU 都会跑一个线程，那么你的任务在某一刻就是真正并发执行了。

（2）CPU Register

CPU Register也就是 CPU 寄存器。CPU 寄存器是 CPU 内部集成的，在寄存器上执行操作的效率要比在主存上高出几个数量级。

（3）CPU Cache Memory

CPU Cache Memory也就是 CPU 高速缓存，相对于寄存器来说，通常也可以成为 L2 二级缓存。相对于硬盘读取速度来说内存读取的效率非常高，但是与 CPU 还是相差数量级，所以在 CPU 和主存间引入了多级缓存，目的是为了做一下缓冲。

（4）Main Memory

Main Memory 就是主存，主存比 L1、L2 缓存要大很多。

注意：部分高端机器还有 L3 三级缓存。

L3或L2会有共享的情况，只有L1的时候不会；

## 1.2. CPU与缓存一致性问题

由于主存与 CPU 处理器的运算能力之间有数量级的差距，所以在传统计算机内存架构中会引入高速缓存来作为主存和处理器之间的缓冲

**当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。**

下图为单CPU双核的缓存结构

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204070955537.png" alt="image-20220407095544346" style="zoom:67%;" />

**单线程。**cpu核心的缓存只被一个线程访问。缓存独占，不会出现访问冲突等问题。

**单核CPU，多线程。**进程中的多个线程会同时访问进程中的共享数据，CPU将某块内存加载到缓存后，不同线程在访问相同的物理地址的时候，都会映射到相同的缓存位置，这样即使发生线程的切换，缓存仍然不会失效。但由于任何时刻只能有一个线程在执行，因此不会出现缓存访问冲突。

**多核CPU，多线程。**每个核都至少有一个L1 缓存。多个线程访问进程中的某个共享内存，且这多个线程分别在不同的核心上执行，则每个核心都会在各自的caehe中保留一份共享内存的缓冲。由于多核是可以并行的，可能会出现多个线程同时写各自的缓存的情况，而各自的cache之间的数据就有可能不同。

使用高速缓存解决了 CPU 和主存速率不匹配的问题，但同时又引入另外一个新问题：缓存一致性问题。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204070953239.png" alt="image-20220407095301210" style="zoom:67%;" />



[类似公司结构](https://www.jianshu.com/p/8420ade6ff76)

> 合伙人1要辞退员工a，合伙人2要给员工a升职，升职后的话他再被辞退需要多个合伙人开会决议。两个合伙人分别把命令下发给了自己的管理人员。合伙人1命令下达后，管理人员a在辞退了员工后，他就知道这个员工被开除了。而合伙人2的管理人员2这时候在没得到消息之前，还认为员工a是在职的，他就欣然的接收了合伙人给他的升职a的命令。

在多CPU的系统中(或者单CPU多核的系统)，每个CPU内核都有自己的高速缓存，它们共享同一主内存(Main Memory)。

`当多个CPU的运算任务都涉及同一块主内存区域时，CPU 会将数据读取复制到缓存中进行运算，这可能会导致各自的缓存数据不一致。`关于同一数据的缓存不一致。

因此需要每个 CPU 访问缓存时遵循一定的协议，在读写数据时根据协议进行操作，共同来维护缓存的一致性。这类协议有 MSI、MESI、MOSI、和 Dragon Protocol 等。

<img src="https://cdn.jsdelivr.net/gh/smileArchitect/assets/202102/20210415231224.png" alt="抽象内存架构" style="zoom: 33%;" />

## 1.3. 处理器优化和指令重排序

为了提升性能在 CPU 和主内存之间增加了高速缓存，但在多线程并发场景可能会遇到`缓存一致性问题`。那还有没有办法进一步提升 CPU 的执行效率呢？答案是：处理器优化。

> 为了使处理器内部的运算单元能够最大化被充分利用，处理器会对输入代码进行乱序执行处理，这就是**处理器优化**。

除了处理器会对代码进行优化处理，很多现代编程语言的编译器也会做类似的优化，比如像 Java 的即时编译器（JIT）会做**指令重排序**。

![](https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204052049801.png)

> 处理器优化其实也是重排序的一种类型，这里总结一下，重排序可以分为三种类型：
>
> - 编译器优化的重排序。编译器在不改变单线程程序语义放入前提下，可以重新安排语句的执行顺序。
> - 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。**如果不存在数据依赖性**，处理器可以改变语句对应机器指令的执行顺序。
> - 内存系统的重排序。由于处理器使用缓存和读写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

# 2. 并发编程的问题

## 2.1 原子性

**原子性**是指在一个操作中就是cpu不可以在中途暂停然后再调度，既不被中断操作，要不执行完成，要不就不执行。

一个操作不可分割，不可中断，一个线程在执行中不会倍其他线程干扰。

```java
int i = 2;
int j = i;
i++;
i = i + 1;
```

第一句是基本类型赋值操作，必定是原子性操作。

第二句先读取i的值，再赋值到j，读写两步操作，不能保证原子性。

第三和第四句其实是等效的，先读取i的值，再+1，最后赋值到i，三步操作了，不能保证原子性。

## 2.2 可见性

**可见性**是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

## 2.3 有序性

**有序性**即程序执行的顺序按照代码的先后顺序执行。

### 指令重排序

编译器和处理器为了优化程序性能而对指令序列重新排序的手段。

比如执行

```java
int[][] b = new int[1024][1024]; // B
int a = 1; // A
```

B的代码执行时间显然比A慢，此时可能会先去执行A，再去执行B，提高编译器和处理器的性能效率、并行度。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204071352225.png" alt="image-20220407135200067" style="zoom: 50%;" />

#### 重排序的原则

1. 在单线程中不改变运行结果
2. 操作不具备数据依赖性

**数据依赖性**：若果两个操作访问同一个变量，并且其中一个操作是写操作，那么这两个操作就具备数据依赖性

```java
int a = 1;      // A
int b = 2;      // B 
int c = a * b;  // C
```

可以有两种顺序，ABC或BAC

#### 重排序对多线程的影响

```java
class ReorderExample {
    int a = 0;
    boolean flag = false;

    public void writer() {
        a = 1; // 1
        flag = true; // 2
    } 
    public void reader() {
        if (flag) { // 3
            int i = a * a; // 4
        }
    }
}
```

假设现在有A和B两个下次，此时A线程执行write()方法，B线程执行reader()方法，那么在线程B在执行操作4时，能否获取到a=1呢？答案是不一定。

由于操作1 和操作2没有数据依赖性，因此编译器和处理器能够对这2个操作进行重排序，当操作1和操作2进行重排序时，此时程序的执行时序图是这样子的

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204071023035.png" alt="image-20220407102332540" style="zoom:80%;" />

如上图所示，操作1和操作2做了重排序。程序执行时，线程A首先写标记变量flag，随后线程B读这个变量。由于条件判断为真，线程B将读取变量a。此时，变量a还根本没有被线程A写入，在这里多线程程序的语义被重排序破坏了！

下面是操作3和操作4重排序后，程序的执行时序图：

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204071022985.png" alt="image-20220407102239983" style="zoom:80%;" />

在程序中，操作3和操作4存在控制依赖关系。当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程B的处理器可以提前读取并计算a*a，然后把计算结果临时保存到一个名为重排序缓冲（reorder buffer ROB）的硬件缓存中。当接下来操作3的条件判断为真时，就把该计算结果写入变量i中。

从图中我们可以看出，猜测执行实质上对操作3和4做了重排序。重排序在这里破坏了多线程程序的语义！

**重排序对单线程的执行结果没有影响，但是在多线程中，重排序可能会改变程序执行的结果**。

## 总结

> 缓存一致性问题其实就是可见性问题
>
> 处理器优化可能会造成原子性问题
>
> 指令重排序会造成有序性问题

出了问题总是要解决的，那有什么办法呢？首先想到简单粗暴的办法，干掉缓存让 CPU 直接与主内存交互就解决了可见性问题，禁止处理器优化和指令重排序就解决了原子性和有序性问题，但这样一夜回到解放前了，显然不可取。

所以技术前辈们想到了在物理机器上定义出一套内存模型

**为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范。**

内存模型解决并发问题主要采用两种方式：`限制处理器优化`和`使用内存屏障`。

# 3. Java 内存模型

同一套内存模型规范，不同语言在实现上可能会有些差别。

> Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。
>
> **目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。**

## 3.1. Java 运行时内存区域与硬件内存的关系

了解过 JVM 的同学都知道，JVM 运行时内存区域是分片的，分为栈、堆等，其实这些都是 JVM 定义的逻辑概念。在传统的硬件内存架构中是没有栈和堆这种概念。

![](https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204052050766.png)

从图中可以看出栈和堆既存在于高速缓存中又存在于主内存中，所以**两者并没有很直接的关系。**

## 3.2. Java 内存模型的规范

Java 内存模型是一种规范，定义了很多东西：

- **所有的变量都存储在主内存（Main Memory）中**。包括实例变量，静态变量，但是不包括局部变量和方法参数
- 每个线程都有一个私有的本地内存（Local Memory），**本地内存中存储了该线程以读/写共享变量的拷贝副本。**
- **线程对变量的所有操作都必须在本地内存中进行，而不能直接读写主内存**。
- 不同的线程之间无法直接访问对方本地内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。

而JMM就作用于工作内存和主存之间数据同步过程。他规定了如何做数据同步以及什么时候做数据同步。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204052050718.png" style="zoom: 50%;" />

> 注意：工作内存也就是本地内存的意思。
>
> 如果一定要勉强对应起来的话，从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分。工作内存则对应于虚拟机栈中的部分区域。

## 3.3. Java中解决原子性有序性一致性

### 原子性

在Java中，为了保证原子性，提供了两个高级的字节码指令`monitorenter`和`monitorexit`。这两个字节码，在Java中对应的关键字就是`synchronized`。

因此，在Java中可以使用`synchronized`来保证方法和代码块内的操作是原子性的。

### 可见性

Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值的这种依赖主内存作为传递媒介的方式来实现的。

Java中的`volatile`关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次是用之前都从主内存刷新。因此，可以使用`volatile`来保证多线程操作时变量的可见性。

除了`volatile`，Java中的`synchronized`和`final`两个关键字也可以实现可见性。只不过实现方式不同，这里不再展开了。

### 有序性

在Java中，可以使用`synchronized`和`volatile`来保证多线程之间操作的有序性。实现方式有所区别：

`volatile`关键字会禁止指令重排。`synchronized`关键字保证同一时刻只允许一条线程操作。

### 总结

好像`synchronized`关键字是万能的，他可以同时满足以上三种特性，但是`synchronized`是比较影响性能的，虽然编译器提供了很多锁优化技术，但是也不建议过度使用。

## 3.4. 线程间通信 - 八种内存交互操作

如果两个线程都对一个共享变量进行操作，共享变量初始值为 1，每个线程都变量进行加 1，预期共享变量的值为 3。在 JMM 规范下会有一系列的操作。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204052050409.png" style="zoom:50%;" />

为了更好的控制主内存和本地内存的交互，Java 内存模型定义了八种操作来实现：

- **lock**：锁定。作用于**主内存**的变量，把一个变量标识为一条线程独占状态。
- **read**：读取。作用于**主内存**变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用
- **load**：载入。作用于**工作内存**的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。
- **use**：使用。作用于**工作内存**的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。
- **assign**：赋值。作用于**工作内存**的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。
- **store**：存储。作用于**工作内存**的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。
- **write**：写入。作用于**主内存**的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。
- **unlock**：解锁。作用于**主内存**变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。

<img src="/Users/milk/Library/Application Support/typora-user-images/image-20220407105226340.png" alt="image-20220407105226340" style="zoom:80%;" />

使用规则：

- 不允许read、load、store、write操作之一单独出现，也就是read操作后必须load，store操作后必须write。
- 不允许线程丢弃他最近的assign操作，即工作内存中的变量数据改变了之后，必须告知主存。
- 不允许线程将没有assign的数据从工作内存同步到主内存。
- 一个新的变量必须在主内存中诞生，不允许工作内存直接使用一个未被初始化的变量。就是对变量实施use、store操作之前，必须经过load和assign操作。
- 一个变量同一时间只能有一个线程对其进行lock操作。多次lock之后，必须执行相同次数unlock才可以解锁。
- 如果对一个变量进行lock操作，会清空所有工作内存中此变量的值。在执行引擎使用这个变量前，必须重新load或assign操作初始化变量的值。
- 如果一个变量没有被lock，就不能对其进行unlock操作。也不能unlock一个被其他线程锁住的变量。
- 一个线程对一个变量进行unlock操作之前，必须先把此变量同步回主内存。

# 4. 有态度的总结

由于CPU 和主内存间存在数量级的速率差，想到了引入了多级高速缓存的传统硬件内存架构来解决，多级高速缓存作为 CPU 和主内间的缓冲提升了整体性能。解决了速率差的问题，却又带来了缓存一致性问题。

数据同时存在于高速缓存和主内存中，如果不加以规范势必造成灾难，因此在传统机器上又抽象出了内存模型。

Java 语言在遵循内存模型的基础上推出了 JMM 规范，目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。

为了更精准控制工作内存和主内存间的交互，JMM 还定义了八种操作：`lock`, `unlock`, `read`, `load`,` use`,` assign`, `store`, `write`。



# volatile

## 作用

1. 保证线程间变量的可见性
2. 禁止CPU进行指令重排序

## 保持可见性的大致流程：

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204071337351.png" alt="image-20220407133715250" style="zoom:80%;" />

## 禁止重排序的原理

首先要讲一下内存屏障，内存屏障可以分为以下几类：

- LoadLoad 屏障：对于这样的语句Load1，LoadLoad，Load2。在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。
- StoreStore屏障：对于这样的语句Store1， StoreStore， Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。
- LoadStore 屏障：对于这样的语句Load1， LoadStore，Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。
- StoreLoad 屏障：对于这样的语句Store1， StoreLoad，Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。

在每个volatile读操作后插入LoadLoad屏障，在读操作后插入LoadStore屏障。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204071343651.png" alt="image-20220407134352384" style="zoom:80%;" />

在每个volatile写操作的前面插入一个StoreStore屏障，后面插入一个SotreLoad屏障。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204071344997.png" alt="image-20220407134418567" style="zoom:80%;" />
