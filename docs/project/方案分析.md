# 海量数据处理

[参考]([https://blog.csdn.net/qq_41058526/article/details/89313852?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166423998316800182729596%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=166423998316800182729596&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-89313852-null-null.142](https://blog.csdn.net/qq_41058526/article/details/89313852?ops_request_misc=%7B%22request%5Fid%22%3A%22166423998316800182729596%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&request_id=166423998316800182729596&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-89313852-null-null.142))

1G = 10^9byte = 10亿字节byte = 10亿 * 8bit

2^10 = 10^3

# Top k

### 一、一亿个数中找前100

#### 1、快排

时间复杂度nlogn，空间：一个数字按照4个字节（1Byte字节 = 8bits），最多占用400m

#### 2、堆排序

最小堆，建堆的时间复杂度（mlogm），总时间复杂度nmlogm，空间复杂度100万（即m）

#### 3、分治

1亿个数分成100份，每份100万，分别找前100，再合在一起一万个数找前100



### 二、海量日志数据，提取出某日访问百度次数最多的那个IP

> IP地址最多有2^32=4G种取值情况，所以不能完全加载到内存中进行处理。

采用映射的方法，比如模1000，把整个大文件映射为1000个小文件

再找出每个小文中出现频率最大的IP（可以采用hashmap进行频率统计，然后再找出频率最大的几个）及相应的频率。然后再在这1000个最大的IP中，找出那个频率最大的IP



### 三、统计最热门的10个查询串

> 搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。
>
> 假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。），请你统计最热门的10个查询串，要求使用的内存不能超过1G。

内存不能超过1G，一千万条记录，每条记录是255Byte，很显然要占据2.375G内存，这个条件就不满足要求了。

#### 第一步：Query统计

##### 方案一：多路归并排序

外部排序指的是大文件的排序，当待排序的文件很大时，无法将整个文件的所有记录同时调入内存进行排序，只能将文件存放在外存，这种排称为外部排序。外部排序的过程主要是依据数据的内外存交换和“内部归并”两者结合起来实现的。

外部排序最常用的算法是多路归并排序，即将原文件分解成多个能够一次性装入内存的部分分别把每一部分调入内存完成排序。然后，对已经排序的子文件进行归并排序。

我们可以采用归并排序，因为归并排序有一个比较好的时间复杂度O(NlgN)。排完序之后我们再对已经有序的Query文件进行遍历，统计每个Query出现的次数，再次写入文件中。综合分析一下，排序的时间复杂度是O(NlgN)，而遍历的时间复杂度是O(N)

**总体时间复杂度：**O(N+NlgN)=O（NlgN）

##### 方案二：哈希表

300万的Query，每个Query255Byte，因此我们可以考虑把他们都放进内存中去，而现在只是需要一个合适的数据结构，在这里，Hash Table绝对是我们优先的选择，因为hashmap的查询速度非常的快，几乎是O(1)的时间复杂度。

维护一个Key为Query字串，Value为该Query出现次数的hashmap，每次读取一个Query，如果该字串不在Table中，那么加入该字串，并且将Value值设为1；如果该字串在Table中，那么将该字串的计数加一即可。最终在O(N)的时间复杂度内完成了对该海量数据的处理。



#### 第二步：找出Top10

维护一个K(该题目中是10)大小的小根堆，然后遍历300万的Query，分别和根元素进行对比。

最先遍历到的k个数存放到最小堆中，并假设它们就是我们要找的最大的k个数，X1>X2...Xmin(堆顶)

而后遍历后续的N-K个数，一一与堆顶元素进行比较，如果遍历到的Xi大于堆顶元素Xmin，则把Xi放入堆中，而后更新整个堆，更新的时间复杂度为logK，如果Xi<Xmin，则不更新堆。



### 四、有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词

（1）分文件（在外存中进行）

顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件（记为x0,x1,...x4999）中。这样每个文件大概是200k左右。

如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。

（2）文件内排序（内存中）

对每个小文件，统计每个文件中出现的词以及相应的频率（可以采用trie树/hash_map等），并取出出现频率最大的100个词（可以用含100个结点的最小堆），并把100个词及相应的频率存入文件，这样又得到了5000个文件。

（3）归并

下一步就是把这5000个文件进行归并（类似与归并排序）的过程了。




# int数字的重复数据查找（bitmap）

### 一、在2.5亿个整数中找出不重复的整数（内存不足以容纳这2.5亿个整数）

int有4个字节，32位bit，最多可表示 2^32 个正整数，即4G个正整数(1G=2^30）

#### 方案一

用Bitmap法，每个正整数用两个bit的标志位，00表示没有出现，01表示出现1次，10表示出现多次。

开辟一个用Bitmap法标志4G个正整数的桶数组，则总共需要4G*2bit=1G内存。

然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。

新开数组的所需大小并不取决于数据量的大小，而是取决于某数据值的大小。

#### 方案二

进行划分小文件的方法。然后在小文件中找出不重复的整数，并排序。然后再进行归并，注意去除重复的元素。



### 二、给40亿个不重复的int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中

快速排序+二分查找过于慢。

申请512M的内存，一个bit位代表一个int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。



### 三、超大文件取数字交集

现有两个各有20亿行的文件，每一行都只有一个数字，求这两个文件的交集。

因为int的最大数是2^32 - 1 = 4G，用一个二进制的下标来表示一个int值，大概需要4G个bit位，即约4G/8 = 552M的内存。

**如果都是正数：**

用int存的话，4G bit/32b = 2的32次/2的5次 = 2的27次 = 128M个

建立int [128M] 的数组，对于每个数，先 /32，确定在数组哪个位置，然后%32，确定在该int的哪一位

然后对这个数组取并集即可统计



# 字符串统计（trie树）

### 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词

用trie树统计每个词出现的次数，时间复杂度是O(n*le)（le表示单词的平准长度）。

然后是找出出现最频繁的前10个词，可以用堆来实现，前面的题中已经讲到了，时间复杂度是O(n*lg10)。

**总的时间复杂度**，是`O(n*le)`与`O(n*lg10)`中较大的哪一个。

trie统计可以减少内存空间，并且加快字符串比较时间



# 海量数据中位数

### 一、只有2G内存的pc机，在一个存有10G个整数的文件，从中找到中位数，写一个算法。

**关于中位数**：数据排序后，位置在最中间的数值。即将数据分成两部分，一部分大于该数值，一部分小于该数值。中位数的位置：当样本数为奇数时，中位数=(N+1)/2 ; 当样本数为偶数时，中位数为N/2与1+N/2的均值（那么10G个数的中位数，就第5G大的数与第5G+1大的数的均值了）。

**分析**：

1. 原数据不能读进内存，不然可以用快速选择，如果数的范围合适的话还可以考虑桶排序或者计数排序，但这里假设是32位整数，仍有4G种取值，需要一个16G大小的数组来计数。
2. 若看成从N个数中找出第K大的数，如果K个数可以读进内存，可以利用最小或最大堆，但这里K=N/2,有5G个数，仍然不能读进内存。



解法：**桶排序**

首先假设是32位无符号整数。整数范围是0 - 2^32 - 1，一共有4G种取值

故需划分区间，每个区间用来计数，需要计数的下10G（10*2^32 ）这么大的数，因为可能一个数字重复10G次，故每个区间最少需要64位无符号整数来作为计数，即8B

故区间个数共：2G/8B = 256M个

要把4G个数映射到256M个区间，每个区段有16（4G/256M = 16）种值，每16个值算一段， 0～15是第1段，16～31是第2段，……2^32-16 ～2^32-1是第256M段。

**操作**：

1. 读一遍10G个整数，把整数映射到256M个区段中，用一个64位无符号整数给每个相应区段记数。

2. 从前到后对每一段的计数累加，当累加的和超过5G时停止，找出这个区段（即累加停止时达到的区段，也是中位数所在的区段）的数值范围，设为[a，a+15]，同时记录累加到前一个区段的总数，设为m。然后，释放除这个区段占用的内存。

3. 再读一遍10G个整数，把在[a，a+15]内的每个值计数，即有16个计数。

4. 对新的计数依次累加，每次的和设为n，当m+n的值超过5G时停止，此时的这个计数所对应的数就是中位数。

 **复杂度**：

上面的海量数据寻找中位数，其实就是利用了“分割”思想，每次将 问题空间 大约分解成原问题空间的一半左右。（划分成两个文件，直接丢弃其中一个文件），故总的复杂度可视为O(logN) N=10亿。


### 二、**利用二进制分文件 &&** 快速排序算法中的“分割思想”

2的10次 = 10的3次

10亿个数字，每个数字在内存中占4B，10亿个数字完全加载到内存中需要：10*108*4B ，约为：4GB内存。显然不能把所有的数字都装入内存。

具体如下：

（1）利用二进制分文件

假设10亿个数字保存在一个大文件中，依次读一部分文件到内存(不超过内存的限制：1GB)，将每个数字用二进制表示，比较二进制的最高位(第32位)，如果数字的最高位为0，则将这个数字写入 file_0文件中；如果最高位为 1，则将该数字写入file_1文件中。【这里的最高位类似于快速排序中的枢轴元素】

从而将10亿个数字分成了两个文件（几乎是二分的），假设 file_0文件中有 6亿 个数字，file_1文件中有 4亿 个数字。那么中位数就在 file_0 文件中，并且是 file_0 文件中所有数字排序之后的第 1亿 个数字。

【为什么呢？因为10亿个数字的中位数是10亿个数排序之后的第5亿个数。现在file_0有6亿个数，file_1有4亿个数，file_0中的数都比file_1中的数要大（最高位为符号位，file_1中的数都是负数，file_0中的数都是正数，也即这里一共只有4亿个负数，排序之后的第5亿个数一定是正数，那么排序之后的第5亿个数一定位于file_0中）】。除去4亿个负数，中位数就是6亿个正数从小到大排序之后 的第 1 亿个数。

现在，我们只需要处理 file_0 文件了（不需要再考虑file_1文件）。对于 file_0 文件，同样采取上面的措施处理：将file_0文件依次读一部分到内存(不超内存限制：1GB)，将每个数字用二进制表示，比较二进制的 次高位（第31位），如果数字的次高位为0，写入file_0_0文件中；如果次高位为1，写入file_0_1文件 中。

现假设 file_0_0文件中有3亿个数字，file_0_1中也有3亿个数字，则中位数就是：file_0_0文件中的数字从小到大排序之后的第1亿个数字。

抛弃file_0_1文件，继续对 file_0_0文件 根据 次次高位(第30位) 划分，假设此次划分的两个文件为：file_0_0_0中有0.5亿个数字，file_0_0_1中有2.5亿个数字，那么中位数就是 file_0_0_1文件中的所有数字排序之后的 第 0.5亿 个数。

......

（2）快速排序算法中的“分割思想”

按照上述思路，直到划分的文件可直接加载进内存时（比如划分的文件中只有5KW个数字了），就可以直接对数字进行快速排序，找出中位数了。当然，你也使用“快排的分割算法”来找出中位数(比使用快速排序要快)




# 100000个玩家的战斗力，要排名前500名，而且需要实时更新，怎么处理？

第一、100000名**实时遍历系统一定承受不了**或者说这样做代价太大，那么可以首先遍历一遍，**挑选出战斗力最高的1000名**，**然后后面只遍历这1000名就可以了**，因为前500名大概率都是前一千名产生的，减少系统开销。

第二、为了防止某些玩家充钱了，大幅提升战斗力，那么可以设置一个阈值，**如果某个玩家战斗力增加速度超过阈值**，**那么这个玩家也应该纳入实时排序过程中**。

第三、最后100000名玩家的战斗力可以定期在服务器压力不大的时候，**比如休服时期或者夜间**，**做整体排序**，以便校验数据的准确性。




# 100万行的表实时反馈有错误的行

多线程，线程池，分区间进行遍历





# 如何在一个1到100的整数数组中找到丢失的数字?

### 1、丢了一个

用总和-累加和，即该数字

### 2、丢了多个

创建长100的boolean数组，遍历有的就true

剩下的false就是缺少的数



# 两个50亿的url文件，找出相同的url

- 给A，B两个文件，各存放50亿条URL，每条URL占用64个字节，内存限制为4G，找出A，B中相同的URL。

1G = 10^9byte = 10亿字节

### 方案1

可以估计每个文件的大小为5G×64=32G，远远大于内存限制的4G。所以不可能将其完全加载到内存中处理。考虑采取分而治之的方法。

遍历文件a，对每个url求取hashcode，然后根据hash分成1000个小文件，记为ai，每个小文件就只有32m。同样的遍历b。

这样处理后，因为是取的hash，所以相同的url在对应序号的文件对中，比如a32和b32。

分别对每对小文件查找相同url，先将ai存到set中，遍历bi查看是否a.contains()。

### 方案2

如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示320亿bit。将其中一个文件中的url使用Bloom filter映射为这320亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）。

> hash后要判断每个文件大小，如果hash分的不均衡有文件较大，还应继续hash分文件，换个hash算法第二次再分较大的文件，一直分到没有较大的文件为止。这样文件标号可以用A1-2表示（第一次hash编号为1，文件较大所以参加第二次hash，编号为2）
>
> 由于1存在，第一次hash如果有大文件，不能用直接set的方法。建议对每个文件都先用字符串自然顺序排序，然后具有相同hash编号的（如都是1-3，而不能a编号是1，b编号是1-1和1-2），可以直接从头到尾比较一遍。对于层级不一致的，如a1，b有1-1，1-2-1，1-2-2，层级浅的要和层级深的每个文件都比较一次，才能确认每个相同的url。
> 



# 8G的int型数据，计算机的内存只有2G，怎么对它进行排序？（外部排序）

可以使用外部排序来对它进行处理。

首先将整个文件分成许多份，比如说m份，划分的依据就是使得**每一份的大小都能放到内存里**。然后我们用快速排序或者堆排序等方法对每一份数据进行一个**内部排序**，变成有序子串。接着对这m份有序子串进行**m路归并排序**。

取这m份数据的最小元素，进行排序，输出排序后最小的元素到磁盘中，同时从该元素所在子串中读入一个元素，直到所有数据都被输出到结果中为止。

注意: **读取的时候是每次读取m个int数**，**通过比较之后再输出**。



## [CPU飙升怎么排查](https://blog.csdn.net/m0_37542440/article/details/123679011)

1. top
	查看所有进程占系统cpu的排序，极大可能排第一的就是自己的java进程，pid就是进程号。

	或ps -ef|grep java

2. `top -Hp <pid>`

	查看Java进程下的所有线程占用cpu的情况，找到高负荷线程号

3. 将高负荷线程号转换为16进制，`printf "%x\n" <pid>`

	后续查看线程堆栈信息展示的都是十六进制，为了找到咱们的线程堆栈信息，需要把线程号转为16进制。

4. 使用jstack查询线程堆栈信息

	`jstack <pid> | grep -a 线程id（十六进制）`



### 原因分析

1. 内存消耗过多，导致Full GC次数过多；是否内存溢出，查看哪些对象使用较多
2. 是否线程数过多，导致CPU过高
3. 线程阻塞，死锁
4. 大量递归



### 补充

**Java高CPU占用排查步骤**

- top：找到占用CPU高的进程PID
- jstack PID >> java_stack.log：导出CPU占用高进程的线程栈
- top -Hp PID：找出PID的进程占用CPU过高的线程tid。（或使用命令 ps -mp PID -o THREAD,tid,time | sort -rn | less）
- printf “%x\n” tid：将需要的线程ID转换为16进制格式。
- less java_stack.log：查找转换成为16进制的线程TID，找到对应的线程栈，分析并处理问题。

**Java高内存占用排查步骤**

- top：找到占用内存(RES列)高的Java进程PID。
- jmap -heap PID：查看heap内存使用情况。
- jps -lv ：查看JVM参数配置。
- jstat -gc PID 1000：收集每秒堆的各个区域具体占用大小的gc信息。
- jmap -dump:live,format=b,file=heap_dump.hprof PID ：导出堆文件。
- 使用MAT打开堆文件，分析问题。

**Java堆外内存泄漏排查步骤**

- top：找到占用内存(RES列)较高的Java进程PID。
- jstat -gcutil PID 1000 查看每秒各个区域占堆百分比，若gc正常，则分析堆外内存使用情况。
- jcmd PID VM.native_memory detail，该命令需要添加JVM参数 -XX:NativeMemoryTracking=detail，并重启Java进程才能生效，该命令会显示内存使用情况，查看输出结果，总的committed的内存是否小于物理内存（RES），因为jcmd命令显示的内存包含堆内内存、Code区域、通过unsafe.allocateMemory和DirectByteBuffer申请的内存，但是不包含其他Native Code（C代码）申请的堆外内存。
- pmap -x PID | sort -rn -k 3：查看内存分布，是否有地址空间不在jcmd命令所给出的地址空间中。
- 用工具定位堆外内存，如gperftools、gdb、strace等。



# 15分钟未支付取消订单

## 一、利用任务调度定时任务轮训订单表

### 方案描述

每隔n分钟，搜索订单表中**订单时间>15分钟**的记录，将订单状态改为取消。

### 实现细则

- 单体应用：利用Spring-Task或者Quartz等单机任务调度工具定时执行
- 集群环境：利用分布式任务调度工具XXL-JOB

### 优势

实现简单

### 劣势

时效性差，n分钟扫描一次，订单状态不能及时更新。

n秒钟扫描一次，订单表查询压力大。



## 二、Redis6客户端缓存监听

### 方案描述

Redis6客户端缓存监听方案，监听Redis6数据变化

### 实现细则

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202207151115249.png" alt="iShot_2022-07-15_11.12.44" style="zoom:50%;" />

除了在数据库中写数据，还需要将当前未支付订单的编号放入redis的set集合中

再单独创建kv，key -> 订单编号，value -> 创建订单的实例，900s。

取消订单的时候通过查找，由实例进行取消。

发现超时后，会**主动推送给产生订单的实例**

- 实现

修改redis的redis.conf文件

找到 notify-keyspace-events Ex 这一行 取消行前边的注释 开启键空间失效通知

新建Listener

```java
@Component
@Slf4j
public class RedisKeyExpirationListener extends KeyExpirationEventMessageListener {

    @Autowired
    private OrderService orderService;

    public RedisKeyExpirationListener(RedisMessageListenerContainer listenerContainer) {
        super(listenerContainer);
    }

    @Override
    public void onMessage(Message message, byte[] pattern) {
        // 用户做自己的业务处理即可,注意message.toString()可以获取失效的key
        String expiredKey = message.toString();
        log.info("------------------redis key 失效; key = " + expiredKey);
        if (expiredKey.startsWith(GlobalConstant.RedisPrefixKey.ORDER_PREFIX)) {
            // 获取订单orderNO
            String orderNo = expiredKey.substring(expiredKey.lastIndexOf(":")+1);
            // 将待支付的订单改为已取消(超时未支付)
            orderService.orderPaidTimeout(orderNo);
        }
    }
}
```

新建配置类

```java
@Configuration
public class RedisListenerConfig {

    @Bean
    RedisMessageListenerContainer container(RedisConnectionFactory connectionFactory) {
        RedisMessageListenerContainer container = new RedisMessageListenerContainer();
        container.setConnectionFactory(connectionFactory);
        return container;
    }

}
```

### 优势

及时有效，具备主动推送功能

集群友好，哪个实例发起的订单哪个实例负责取消

### 劣势

基于长链接，连接重启后客户端缓存监听机制会失效，需要手动补偿

实例数量发生变化，需要重新分配



## 三、MQ的延迟队列、死信队列

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202207151156759.png" alt="iShot_2022-07-15_11.55.10" style="zoom:50%;" />

[实现参考](https://blog.csdn.net/isWeisen/article/details/103615519?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1-103615519-blog-112166491.pc_relevant_multi_platform_whitelistv3&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1-103615519-blog-112166491.pc_relevant_multi_platform_whitelistv3&utm_relevant_index=1)

下单之后，将取消订单的消息交给消息队列。

如果时间到了之后，去查看该订单是否已经支付，如果未支付，就取消掉，就是将这个过程交给消息队列去完成。



