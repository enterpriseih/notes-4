# 简介

以商品订单场景为例，

- 如果商品服务和订单服务是两个不同的微服务，在下单的过程中订单服务需要调用商品服务进行扣库存操作。
- 按照传统的方式，下单过程要等到调用完毕之后才能返回下单成功，如果网络产生波动等原因使得商品服务扣库存延迟或者失败，会带来较差的用户体验，
- 如果在高并发的场景下，这样的处理显然是不合适的，那怎么进行优化呢？这就需要消息队列登场了。

消息队列提供一个**异步通信机制**，消息的发送者不必一直等待到消息被成功处理才返回，而是立即返回。

消息中间件负责处理网络通信，如果网络连接不可用，消息被暂存于队列当中，当网络畅通的时候在将消息转发给相应的应用程序或者服务，当然前提是这些服务订阅了该队列。

如果在商品服务和订单服务之间使用消息中间件，既可以**提高并发量**，又**降低服务之间的耦合度**。

目前使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ

# 应用场景

## 1、异步处理

- 把消息放入消息中间件中，等到需要的时候再去处理。

场景说明：用户注册后，需要发注册邮件和注册短信。

传统的做法有两种 

1. 串行方式

	将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端。

	<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202206121128604.png" alt="在这里插入图片描述"  />

2. 并行方式

	将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间

	<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202206121136451.png" alt="e37ba354bd0344d4bcd22543f66ce46b"  />

	

- 引入消息队列，将不是必须的业务逻辑，异步处理。改造后的架构如下：

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202206121142425.png" alt="2ec7b11bcab54cd4b89f93f5db3a24f8"  />

按照以上约定，用户的响应时间相当于是注册信息写入数据库的时间，也就是50毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。因此架构改变后，系统的吞吐量提高到每秒20 QPS。比串行提高了3倍，比并行提高了两倍。

## 2、流量削峰

流量削锋也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。

应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。

为解决这个问题，使用消息队列，当消息队列满了就拒绝响应，跳转到错误页面，这样就可以使得系统不会因为超负载而崩溃。

a、可以控制活动的人数

b、可以缓解短时间内高流量压垮应用

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202206121148575.png" alt="在这里插入图片描述"/>

- 用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面。

秒杀业务根据消息队列中的请求信息，再做后续处理

## 3、日志处理

日志处理是指将消息队列用在日志处理中，比如 Kafka 的应用，解决大量日志传输的问题。架构简化如下

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202206121150882.png" alt="在这里插入图片描述"/>

日志采集客户端，负责日志数据采集，定时写受写入Kafka队列

Kafka消息队列，负责日志数据的接收，存储和转发

日志处理应用：订阅并消费kafka队列中的日志数据

## 4、应用解耦

场景说明：用户下单后，订单系统需要通知库存系统。

传统的做法是，订单系统调用库存系统的接口。如下图：

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202206121144881.png" alt="在这里插入图片描述"/>

传统模式的缺点：假如库存系统无法访问，则订单减库存将失败，从而导致订单失败，订单系统与库存系统耦合

引入消息队列后

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202206121145208.png" alt="在这里插入图片描述"/>

订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功

库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作

> 假如在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦

## 5、消息通讯

消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等

点对点通讯：

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202206121152000.png" alt="在这里插入图片描述" />

客户端A和客户端B使用同一队列，进行消息通讯。

聊天室通讯：

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202206121152311.png" alt="在这里插入图片描述"/>

客户端A，客户端B，客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。

# MQ核心模型

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202207181425211.png" alt="图片 1" style="zoom: 67%;" />

- 生产者(producer)，主要**生产消息**，并发送给消息队列中，通常有同步、异步两种方式
- 消息队列(message queue)，主要**保存/暂存生产者生产的消息**，并将消息以某种方式告知消费者，消息队列一般具备**消息分类(topic)**的能力，存放消息的队列称为msg queue，broker就是个中间代理。
- 消费者(consumer)，主要**从消息队列取出消息**，并进行消费,这里的取出消息的方式主要有两种（**主动拉取消息、等待推送消息**）

# MQ消息的丢失***

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202207181238308.png" alt="img"  />

不同的MQ有不同的处理方式

## 一、RabbitMQ

### 1、生产者丢失数据

生产者将数据发送到 RabbitMQ 的时候，消息可能因为**网络**等问题在传入过程中给搞丢了。

#### 1.1、生产者端解决方法

- **开启 RabbitMQ 事务**（同步）

开启 RabbitMQ 事务channel.txSelect，然后发送消息，如果消息**没有成功被 RabbitMQ 接收到**，那么**生产者会收到异常报错**，此时就可以回滚事务channel.txRollback，然后重试发送消息；如果**收到了消息**，那么可以**提交事务**channel.txCommit，类似数据库事务机制。

- **开启 confirm 模式**（异步）

在生产者端设置**开启 confirm 模式**之后，每次写的消息都会**分配一个唯一的 id**，然后如果**写入了 RabbitMQ 中**，RabbitMQ 会**回传一个 ack 消息**。如果 RabbitMQ **没能处理**这个消息，会**回调一个 nack 接口**，告诉你这个消息接收失败，你可以重试。

而且可以结合这个机制自己在内存里维护每个消息 id 的状态，**如果超过一定时间还没接收到这个消息的回调，那么你可以重发**。

### 2、消息队列丢失数据

**开启 RabbitMQ 的持久化**，就是**消息写入之后会持久化到磁盘**，**消息队列宕机恢复之后会自动读取之前存储的数据**，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，可能导致少量数据丢失，但是这个概率较小。

#### 2.1、开启 RabbitMQ 的持久化

1. 创建 **queue** 的时候将其设置为持久化；保证 RabbitMQ 持久化 queue 的**元数据**，但是它是不会持久化 queue 里的数据的。
2. **`deliveryMode`** 设置为 2。即将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。

#### 2.2、持久化机制与生产者的 confirm 机制配合

开启 RabbitMQ 的持久化机制，也有一种可能 ，就是这个消息写到了 RabbitMQ 中，但是**还没来得及持久化到磁盘上**，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。

所以，持久化可以跟生产者那边的 confirm 机制配合起来，**只有消息被持久化到磁盘之后，才会通知生产者 ack **，这样哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 ack，需要自己重发。

### 3、消费端丢失数据

主要是**因为消费的时候，刚消费到，还没处理，结果消费进程挂了。**导致RabbitMQ 认为已经消费了数据。

#### 3.1、关闭 RabbitMQ 的自动 ack

关闭 RabbitMQ 的自动 ack，可以通过一个 api 来调用，确保每次**数据处理完后手动 ack**。**没有返回 ack**，那 RabbitMQ 就认为你还**没处理完**。

如果消费者返回 ack 之前断开了连接，RabbitMQ 会重新分发给下一个消费者。

> RabbitMQ不会为未ack的消息设置超时时间，它判断此消息是**否需要重新投递给消费者的唯一依据**是消费该消息的**消费者连接是否已经断开**。这么设计的原因是RabbitMQ**允许消费者消费一条消息的时间可以很长**。保证数据的最终一致性。

## 二、Kafka

### 1、生产者

设置ack

### 2、Kafka

一般来讲Kafka有副本，可以同步。

但有一个特殊场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。但是**此时其他的 follower 刚好还有一部分数据没有同步**，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就丢失了一些数据？

可以进行如下设置：

- topic 设置 `replication.factor`大于1，保证每个分区至少有2个副本。
- Kafka 服务端设置 `min.insync.replicas` 大于1，要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower ，可被选举为leader。
- producer 端设置 `acks=all`：要求每条数据，必须是**写入所有 replica 之后，才能认为是写成功了**。
- producer 端设置 `retries=MAX`（无限次重试）：这个是**要求一旦写入失败，就无限重试**。

### 3、消费者

关闭自动提交offset



# 消息队列的选型及优缺点

## Kafka

优点： **吞吐量**非常大（生产者异步发送），性能非常好，集群**高可用**。

- 高吞吐、低延迟：kakfa 最大的特点就是收发消息非常快，kafka 每秒可以处理几十万条消息，它的最低延迟只有几毫秒；
- 高伸缩性：每个主题(topic) 包含多个分区(partition)，主题中的分区可以分布在不同的主机(broker)中；
- 持久性、可靠性：Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，Kafka 底层的数据存储是基于 Zookeeper 存储的，Zookeeper 我们知道它的数据能够持久存储；
- 容错性：非常高，kafka是分布式的，一个数据多个副本，某个节点宕机，Kafka 集群能够正常工作；
- 消息有序：消费者采用Pull方式获取消息，消息有序，通过控制能够保证所有消息被消费且仅被消费一次；

缺点：

- 数据是批量发送的，实时性问题。
- 仅支持统一分区内消息有序。
- 依赖zookeeper进行元数据处理。

使用场景：**日志分析**、大数据采集

## RabbitMQ

优点：消息**可靠性高**，功能全面。异步消息传递：支持多种消息协议，消息队列，传送确认，灵活的路由到队列，多种交换类型

缺点：

- **吞吐量比较低**，消息积累会严重影响性能。
- erlang语言的底层不易阅读，不利于二次开发。
- 集群不支持动态扩展。

使用场景：小规模场景。

## RocketMQ

优点：高吞吐、高性能、高可用，功能非常全面。纯Java开发。

缺点：开源版功能不如云上商业版。官方文档和周边生态还不够成熟。客户端只支持java。

使用场景：目前在阿里集团被广泛应用于交易、充值、流计算、消息推送、日志流式处理、binglog分发等场景。

# MQ的模式

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202207181628773.png" alt="iShot_2022-07-18_16.08.38" style="zoom:50%;" />

#  如何设计一个MQ

1. 实现一个单机的队列数据结构。高效、可扩展。
2. 将单机队列扩展成分布式队列。分布式集群管理。
3. 基于 Topic 定制消息路由策略。发送者路由策略，消费者与队列对应关系，消费者路由关系。
4. 实现高效的网络通信。Netty、Http。
5. 规划日志文件，实现文件高效读写。**零拷贝**、顺序写；服务器重启后，快速恢复。
6. 定制高级功能：死信队列、延迟队列、事务消息等。



# 中间件示例

## 1、电商系统

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202206121154470.png" alt="在这里插入图片描述" />

消息队列采用高可用，可持久化的消息中间件。比如Active MQ，Rabbit MQ，Rocket Mq。

（1）应用将主干逻辑处理完成后，写入消息队列。消息发送是否成功可以开启消息的确认模式。（消息队列返回消息接收成功状态后，应用再返回，这样保障消息的完整性）

（2）扩展流程（发短信，配送处理）订阅队列消息。采用推或拉的方式获取消息并处理。

（3）消息将应用解耦的同时，带来了数据一致性问题，可以采用最终一致性方式解决。比如主数据写入数据库，扩展应用根据消息队列，并结合数据库方式实现基于消息队列的后续处理。


## 2、日志收集系统

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202206121156384.png)

分为Zookeeper注册中心，日志收集客户端，Kafka集群和Storm集群（OtherApp）四部分组成。

Zookeeper注册中心，提出负载均衡和地址查×××

日志收集客户端，用于采集应用系统的日志，并将数据推送到kafka队列

Kafka集群：接收，路由，存储，转发等消息处理

Storm集群：与OtherApp处于同一级别，采用拉的方式消费队列中的数据



# Redis实现消息队列

### https://blog.csdn.net/le_17_4_6/article/details/124457648
