# 概述

SQL 是持久化到硬盘，IO 读取慢

NoSQL (Not Only SQL) 是**内存级别**，读取速度快，减少 IO 操作

- 不遵循 SQL 标准
- 不支持 ACID
- **用不着 sql 的和用了 sql 也不行的情况，请考虑用 NoSql**



Redis：key-value 数据库

MongoDB：document 数据库



查看默认安装目录: /usr/local/bin

redis-benchmark:性能测试工具，可以在自己本子运行，看看自己本子性能如何 

redis-check-aof:修复有问题的 AOF 文件，rdb 和 aof 后面讲 

redis-check-dump:修复有问题的 dump.rdb 文件

redis-sentinel:Redis 集群使用

redis-server:Redis 服务器启动命令

redis-cli:客户端，操作入口

```
复制解压文件里的redis.conf到其他目录
修改复制的文件中的后台启动设置 daemonize no 改成 yes
后台启动启动
redis-server /etc/redis/redis.conf

进入redis
redis-cli -p 6379 -a stackstreammaptointtoarray

关闭
redis-cli -p 6379 shutdown

选择库，0～15
select 0

查看当前数据库的key的数量
dbsize

清空当前库
flushdb

通杀全部库
flushall

```



Redis 是单线程+多路 IO 复用技术

串行 vs 多线程+锁(memcached) vs 单线程+多路 IO 复用(Redis)

Redis 单命令的原子性主要得益于 Redis 的单线程



# Redis单线程快的原因

1、纯**内存**操作

2、基于非阻塞的 IO 多路复用机制

3、**单线程**（其**网络IO**和**键值对读写**是由一个线程完成的）避免了多线程频繁的上下文切换带来的问题



Redis 基于 Reactor 模式开发了网络事件处理器、**文件事件处理器**（file event handler），它是**单线程**的，所以 Redis才叫做单线程的模型。

采用**I/O多路复用机制**来同时监听多个Socket， 根据Socket上的事件类型来选择对应的事件处理器来处理这个事件。可以实现高性能的网络通信模型，又可以跟内部其他单线程的模块进行对接，保证了 Redis 内部的线程模型的简单性。

在 Redis 只运行单线程的情况下，该机制允许内 核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了**一个 Redis 线程处理多个 IO 流的效果**。

> Reactor 模式就是基于建立连接与具体服务之间线程分离的模式。在 Reactor 模式中，会有一个线程（负责与所有客户端建立连接，这个线程通常称之为 Reactor）。
>
> 然后在建立连接之后，Reactor 线程会使用其它线程（可以有多个）来处理与每一个客户端之间的数据传输，这个（些）线程通常称之为 Handler。

### 文件事件处理器四个部分

- 多个 socket(客户端连接)
- IO 多路复用程序(支持多个客户端连接的关键)
- 文件事件分派器(将 socket 关联到相应的事件处理器) 
- 事件处理器(连接应答处理器、命令请求处理器、命令回复处理器)

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202207171259735.png" alt="iShot_2022-07-17_12.58.13" style="zoom:50%;" />

### Redis6.0后加入了多线程，默认关闭

https://mp.weixin.qq.com/s/FZu3acwK6zrCBZQ_3HoUgw

# 为什么要用缓存/Redis

高并发:

一般像 MySQL 这类的数据库的 QPS 大概都在 1w 左右(4 核 8g) ，但是使用 Redis 缓存之后 很容易达到 10w+，甚至最高能达到 30w+(就单机 redis 的情况，redis 集群的话会更高)。

> QPS(Query Per Second)：服务器每秒可以执行的查询次数

# Redis数据结构和常用命令

[常用命令](http://www.redis.cn/commands.html)

```
keys *
查看当前库所有 key (匹配:keys *1) 

exists key 
判断某个 key 是否存在

type key 
查看你的 key 是什么类型

del key 
删除指定的 key 数据

unlink key 
根据 value 选择非阻塞删除
仅将 keys 从 keyspace 元数据中删除，真正的删除会在后续异步操作。

expire key 10 
10秒钟:为给定的 key 设置过期时间

ttl key 
查看还有多少秒过期，-1 表示永不过期，-2 表示已过期

```



Redis是key-value数据库，key的类型只能是String，但是value的数据类型就比较丰富了，主要包括五种：

* String
* Hash
* List
* Set
* Sorted Set

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204162042741.png" style="zoom: 33%;" />

## 1.  String字符串

### 语法

```plain
SET KEY_NAME VALUE
```
string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据。比如 jpg 图片或者序列化的对象。

string 类型是 Redis 最基本的数据类型，一个 value 最大能存储512MB。

```
*EX:key 的超时秒数

setnx key value
只有在key不存在时设置key的值。

get key
查询对应键值

append key value
将给定的value追加到原值的末尾 strlen key 获得值的长度
若没有key，则创建

setnx key value
只有在key不存在时，设置key的值

incr <key>
将 key 中储存的数字值增 1
只能对数字值操作，如果为空，新增值为 1 

decr <key>
将 key 中储存的数字值减 1
只能对数字值操作，如果为空，新增值为-1

incrby / decrby <key><步长>
将 key 中储存的数字值增减。自定义步长。

mset <key1><value1><key2><value2> ..... 
同时设置一个或多个 key-value 对
原子性，有一个失败则都失败

mget <key1><key2><key3> ..... 
同时获取一个或多个 value
原子性，有一个失败则都失败

msetnx <key1><value1><key2><value2> .....
同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。
原子性，有一个失败则都失败

setex <key><过期时间><value>
设置键值的同时，设置过期时间，单位秒

getset <key><value>
以新换旧，设置了新值同时获得旧值。

```

### 数据结构

类似ArrayList

### 场景

实现计数器，session共享，分布式id

比如用户的访问次数、热点文章的点赞转发数量等。

## 2. Hash哈希

**语法**

```plain
HSET KEY_NAME FIELD VALUE
```
Redis hash 是一个键值(key=>value)对集合。

Redis hash 是一个string类型的field和value的映射表，hash特别适合用于存储对象。

就是说 value 存的是 field=>value，像是两层map，key里面还是一个映射表

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204241128839.png" alt="image-20220424112848212" style="zoom:50%;" />

通过 `key(用户ID) + field(属性标签)` 就可以操作对应属性数据了，既不需要重复存储数 据，也不会带来序列化和并发修改控制的问题

```
hget <key1><field>
从<key1>集合<field>取出 value

hmset <key1><field1><value1><field2><value2>... 
批量设置 hash 的值 

hexists <key1><field>查看哈希表 key 中，
给定域 field 是否存在。 

hkeys <key>
列出该 hash 集合的所有 field

hvals <key>
列出该 hash 集合的所有 value

hincrby <key><field><increment>
为哈希表 key 中的域 field 的值加上增量

hsetnx <key><field><value>
将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在

```

**数据结构**

Hash 类型对应的数据结构是两种:ziplist(压缩列表)，hashtable(哈希表)。

当field-value 长度较短且个数较少时，使用 ziplist，否则使用 hashtable。

## 3. List列表

**语法**

```plain
在 key 对应 list 的头部添加字符串元素
LPUSH KEY_NAME VALUE1.. VALUEN

在 key 对应 list 的尾部添加字符串元素
RPUSH KEY_NAME VALUE1..VALUEN

对应 list 中删除 count 个和 value 相同的元素
LREM KEY_NAME COUNT VALUE

返回 key 对应 list 的长度
LLEN KEY_NAME 

```
Redis 列表是简单的字符串列表，按照插入顺序排序，**双向链表**。

可以添加一个元素到列表的头部（左边）或者尾部（右边）

```
lrange <key><start><stop> 
按照索引下标获得元素(从左到右)
lrange mylist 0 -1 
0 左边第一个，-1 右边第一个，(0 -1 表示获取所有)

lpop/rpop <key>
从左边/右边吐出一个值。值在键在，值忘键亡。

rpoplpush <key1><key2>
从<key1>列表右边吐出一个值，插到<key2>列表左边

lindex <key><index>
按照索引下标获得元素(从左到右)

lset<key><index><value>
将列表 key 下标为 index 的值替换成 value

linsert <key> before/after <value><newvalue>
在<value>的前面/后面插入<newvalue>插入值
```



**数据结构**

快速链表 quickList

首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是 ziplist，也即是 压缩列表。

它将所有的元素紧挨着一起存储，分配的是一块连续的内存。 当数据量比较多的时候才会改成 quicklist。

因为普通的链表需要的附加指针空间太大，会比较浪费空间。比如这个列表里存的只是 int 类型的数据，结构上还需要两个额外的指针 prev 和 next。

Redis 将多个 ziplist 用链表结合起来组成了 quicklist。

使用场景：发布与订阅或者说消息队列、慢查询。

## 4. Set集合

### 语法

```plain
SADD KEY_NAME VALUE1...VALUEn
将一个或多个 member 元素加入到集合 key 中，已经存在的 member 元素将被忽略
```
Redis的Set是string类型的**无序**集合。
集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。

```
smembers <key>
取出该集合的所有值。

sismember <key><value>
判断集合<key>是否为含有该<value>值，
有 1，没有 0 

scard <key>
返回该集合的元素个数。

srem <key><value1><value2> .... 
删除集合中的某个元素。

spop <key>
随机从该集合中吐出一个值。

srandmember <key><n>
随机从该集合中取出n个值。不会从集合中删除

smove source destination value 
把集合中一个值从一个集合移动到另一个集合 

sinter <key1><key2>
返回两个集合的交集元素。

sunion <key1><key2>
返回两个集合的并集元素。

sdiff <key1><key2>
返回两个集合的差集元素(key1 中的，不包含 key2 中的)

```

### 数据结构

dict 字典，字典是用哈希表实现

### 举例

https://blog.csdn.net/qq_43514659/article/details/119750751

https://blog.csdn.net/weixin_43989347/article/details/124914215

实现点赞，**key是 博客id**，**value是点赞过的用户id**，value记录哪些用户为该博客id点过赞。

计算集合大小就是点赞数量。



## 5. Sorted Set有序集合(Zset)

### 语法

```plain
ZADD KEY_NAME SCORE1 VALUE1.. SCOREN VALUEN
```
Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。

不同的是每个元素都会关联一个double类型的分数score。

redis**通过score来为集合中的成员进行从小到大的排序**。

zset的成员 (value) 是唯一的，但分数(score)却可以重复。

```
zadd <key><score1><value1><score2><value2>...
将一个或多个 member 元素及其 score 值加入到有序集 key 当中。 

zrange <key><start><stop> [WITHSCORES]
返回有序集 key 中，下标在<start><stop>之间的元素
带 WITHSCORES，可以让分数一起和值返回到结果集。 

zrangebyscore key min max [withscores] [limit offset count]
返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。 
有序集成员按 score 值递增(从小到大)次序排列。

zrevrangebyscore key max min [withscores] [limit offset count] 
同上，改为从大到小排列。

zincrby <key><increment><value> 
为元素的 score 加上增量 

zrem <key><value>
删除该集合下，指定值的元素

zcount <key><min><max>
统计该集合，分数区间内的元素个数 

zrank <key><value>
返回该值在集合中的排名，从 0 开始。

```

zset 底层使用了两个数据结构

(1)、hash，hash 的作用就是关联元素 value 和权重 score，保障元素 value 的唯一性，可以通过元素 value 找到相应的 score 值。

(2)、跳跃表，跳跃表的目的在于给元素 score 排序，根据范围获取元素列表。

（其中每个节点都有指向元素成员的指针和当前元素成员对应的分数）

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204241155884.png" alt="image-20220424115528332" style="zoom:50%;" />

### 场景

实现排行榜功能



## 6. Redis常用命令参考

更多命令语法可以参考官网手册：

[https://www.redis.net.cn/order/](https://www.redis.net.cn/order/)

## 7. Bitmaps

Bitmaps 本身不是一种数据类型， 实际上它就是字符串(key-value) ，但是它可以对字符串的位进行操作。

内部存储的是0和1，其下标叫做偏移量 offset

**语法**

```
setbit<key><offset><value>
设置 Bitmaps 中某个偏移量的值(0 或 1)
```

存储用户活跃量



## 8. HyperLogLog

求集合中不重复元素个数的问题称为**基数问题**

Redis HyperLogLog 是用来做基数统计的算法。

HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。

因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素 本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。

**语法**

```
pfadd <key>< element> [element ...] 
添加指定元素到 HyperLogLog 中
```



## 9. Geospatial

GEO类型：就是是元素的 2 维坐标，在地图上就是经纬度。

redis 基于该类型，提供了经纬度设置，查询，范围查询，距离查询，经纬度 Hash 等常见操作。



# Redis事务机制

## 1. Redis事务生命周期

* **开启事务MULTI**：使用MULTI开启一个事务
* **命令入队列**：每次操作的命令都会加入到一个队列中，但命令此时不会真正被执行
* **提交事务EXEC**：使用EXEC命令提交事务，开始顺序执行队列中的命令
## 2. Redis事务到底是不是原子性的？

先看关系型数据库 ACID 中关于原子性的定义：

**原子性**：一个事务(transaction)中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被恢复(Rollback)到事务开始前的状态，就像这个事务从来没有执行过一样。

官方文档对事务的定义：

* **事务是一个单独的隔离操作**：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。

	Redis 事务的主要作用就是串联多个命令防止别的命令插队。

* 事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。EXEC 命令负责触发并执行事务中的所有命令：如果客户端在使用 MULTI 开启了一个事务之后，却因为断线而没有成功执行 EXEC ，那么事务中的所有命令都不会被执行。另一方面，如果客户端成功在开启事务之后执行 EXEC ，那么事务中的所有命令都会被执行。

官方认为Redis事务是一个原子操作，这是站在执行与否的角度考虑的。

但是从ACID原子性定义来看，**严格意义上讲Redis事务是非原子型的**，因为在命令顺序执行过程中，一旦发生命令执行错误Redis是不会停止执行然后回滚数据。

- **Redis 没有隔离级别概念**：队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行

## 3. Redis为什么不支持回滚（roll back）？

在事务运行期间虽然Redis命令可能会执行失败，但是Redis依然会执行事务内剩余的命令而不会执行回滚操作。

>只有当被调用的Redis命令有语法错误时，这条命令才会执行失败（在将这个命令放入事务队列期间，Redis能够发现此类问题），或者对某个键执行不符合其数据类型的操作：实际上，这就意味着只有程序错误才会导致Redis命令执行失败，这种错误很有可能在程序开发期间发现，一般很少在生产环境发现。
>
>**支持事务回滚能力会导致设计复杂**，这与Redis的初衷相违背，Redis的设计目标是功能简化及确保更快的运行速度。

对于官方的这种理由有一个普遍的反对观点：程序有bug怎么办？但其实回滚不能解决程序的bug，比如某位粗心的程序员计划更新键A，实际上最后更新了键B，回滚机制是没法解决这种人为错误的。正因为这种人为的错误不太可能进入生产系统，所以官方在设计Redis时选用更加简单和快速的方法，没有实现回滚的机制。

## 4. Redis事务失败场景

有三种类型的失败场景：

### （1）在事务提交之前，客户端执行的命令缓存（队列）失败

比如命令的**语法错误**(命令参数个数错误，不支持的命令等等)。

如果发生这种类型的错误，Redis将向客户端返回包含错误提示信息的响应，同时Redis**会清空队列**中的命令并**取消事务**。

```plain
> set name xiaoming # 事务之前执行
OK
> multi # 开启事务
OK
> set name zhangsan # 事务中执行，命令入队列
QUEUED
> setset name zhangsan2 # 错误的命令，模拟失败场景
(error) ERR unknown command `setset`, with args beginning with: `name`, `zhangsan2`,
> exec # 提交事务，发现由于上条命令的错误导致事务已经自动取消了
(error) EXECABORT Transaction discarded because of previous errors.
> get name # 查询name，发现未被修改 
"xiaoming"

```
### （2）事务提交后开始顺序执行命令，之前缓存在队列中的命令有可能执行失败

但只会是**单独那条失败**，**其余的都会执行**

```plain
> multi # 开启事务
OK
> set name xiaoming # 设置名字
QUEUED
> set age 18 # 设置年龄
QUEUED
> lpush age 20 # 此处仅检查是否有语法错误，不会真正执行
QUEUED
> set address beijing
QUEUED
> exec # 提交事务后开始顺序执行命令，第三条命令执行失败
1) OK
2) OK
3) (error) WRONGTYPE Operation against a key holding the wrong kind of value
3) OK
> get name # 第三条命令失败没有将前两条命令回滚 
"xiaoming"

```
### （3）由于乐观锁失败，事务提交时将丢弃之前缓存的所有命令序列

通过开启两个redis客户端并结合watch命令模拟这种失败场景。

```plain
# 客户端1
> set name xiaoming # 客户端1设置name
OK
> watch name # 客户端1通过watch命令给name加乐观锁
OK
# 客户端2
> get name # 客户端2查询name
"xiaoming"
> set name zhangsan # 客户端2修改name值
OK
# 客户端1
> multi # 客户端1开启事务
OK
> set name lisi # 客户端1修改name
QUEUED
> exec # 客户端1提交事务，返回空
(nil)
> get name # 客户端1查询name，发现name没有被修改为lisi
"zhangsan"

```
在事务过程中监控的 key 被其他客户端改变，则当前客户端的乐观锁失败，事务提交时将丢弃所有命令缓存队列。
## 5. Redis事务相关命令

### （1）WATCH

可以为Redis事务提供 check-and-set （CAS）行为。被WATCH的键会被监视，并会发觉这些键是否被改动过了。 

如果有至少一个被监视的键在 EXEC 执行之前**被修改**了， 那么整个**事务**都会被**取消**， EXEC 返回 nil-reply 来表示事务已经失败。

### （2）MULTI

用于开启一个事务，它总是返回OK。MULTI执行之后,客户端可以继续向服务器发送任意多条命令， 这些命令不会立即被执行，而是被放到一个队列中，当 EXEC命令被调用时， 所有队列中的命令才会被执行。

### （3）UNWATCH

取消 WATCH 命令对所有 key 的监视，一般用于DISCARD和EXEC命令之前。

如果在执行 WATCH 命令之后， EXEC 命令或 DISCARD 命令先被执行了的话，那么就不需要再执行 UNWATCH 了。

因为 EXEC 命令会执行事务，因此 WATCH 命令的效果已经产生了；而 DISCARD 命令在取消事务的同时也会取消所有对 key 的监视，因此这两个命令执行之后，就没有必要执行 UNWATCH 了。

### （4）DISCARD

当执行 DISCARD 命令时， 事务会被放弃， 事务队列会被清空，并且客户端会从事务状态中退出。

### （5）EXEC

负责触发并执行事务中的所有命令：

如果客户端成功开启事务后执行EXEC，那么事务中的所有命令都会被执行。

如果客户端在使用MULTI开启了事务后，却因为断线而没有成功执行EXEC，那么事务中的所有命令都不会被执行。

需要特别注意的是：即使事务中有某条/某些命令执行失败了，事务队列中的其他命令仍然会继续执行，Redis不会停止执行事务中的命令，而不会像我们通常使用的关系型数据库一样进行回滚。



# Redis的分区

## Redis的分区作用是什么？

- **扩展数据库容量**，可以利用多台机器的内存构建更大的数据库
- **扩展计算能力**，分区可以在多核和多计算机之间弹性扩展计算能力，在多计算机和网络适配器之间弹性扩展网络带宽

## Redis分区有哪些实现方案？

在介绍Redis集群的实现方案时已经介绍过了**客户端分区**和**代理分区**，常见的Redis分区方案主要有以下三种：

- **客户端分区**：客户端决定数据被存到哪个Redis节点或者从哪个节点读取
- **代理分区**：客户端将请求发送到代理，而不是直接发送到Redis节点，代理根据分区策略将请求发送到Redis节点上
- **查询路由**：客户端随机请求任意一个Redis节点，这个Redis节点将请求转发到正确的Redis节点。Redis Cluster实现了一种混合形式的查询路由，并不是直接将请求从一个Redis节点转发到另一个Redis节点，而是在客户端的帮助下直接重定向到正确的[redis]()节点

## Redis分区的缺点？

- **不支持多个键的操作**，例如不能操作映射在两个Redis实例上的两个集合的交叉集。（其实可以做到这一点，但是需要间接的解决）
- **Redis不支持多个键的事务**
- **Redis是以键来分区**，因此不能使用单个大键对数据集进行分片，例如一个非常大的有序集
- **数据的处理会变得复杂**，比如你必须处理多个RDB和AOF文件，在多个实例和主机之间持久化你的数据
- **添加和删除节点也会变得复杂**，例如通过在运行时添加和删除节点，Redis集群通常支持透明地再均衡数据，但是其他系统像客户端分区或者代理分区的特性就不支持该特性。不过*Pre-sharding*(预分片)可以在这方面提供帮助。

# Redis持久化策略

## 什么是持久化？

持久化（Persistence），即把数据（如内存中的对象）保存到可永久保存的存储设备中（如磁盘）。持久化的主要应用是将内存中的对象存储在数据库中，或者存储在磁盘文件中、XML数据文件中等等。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204241613825.png" width=""/>

还可以从如下两个层面简单的理解持久化 ：

* 应用层：如果关闭(shutdown)你的应用然后重新启动则先前的数据依然存在。
* 系统层：如果关闭(shutdown)你的系统（电脑）然后重新启动则先前的数据依然存在。
## Redis为什么要持久化？

Redis是内存数据库，为了保证效率所有的操作都是在内存中完成。**数据都是缓存在内存中**，当你重启系统或者关闭系统，之前缓存在内存中的数据都会丢失再也不能找回。因此为了避免这种情况，Redis需要实现持久化将内存中的数据存储起来。

## Redis如何实现持久化？

Redis官方提供了不同级别的持久化方式：

* **RDB持久化**：能够在指定的**时间间隔**内将内存中的**数据集快照**写入磁盘。
* **AOF持久化**：记录每次对服务器的**写操作**，当服务器重启的时候会**重新执行这些命令来恢复原始的数据**，AOF命令以redis协议追加保存每次写的操作到文件末尾。Redis还能对AOF文件进行后台重写，使得AOF文件的体积不至于过大。
* 不使用持久化：如果你只希望你的数据在服务器运行的时候存在，你也可以选择不使用任何持久化方式。
* 同时开启RDB和AOF：你也可以同时开启两种持久化方式，在这种情况下当redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。

这么多持久化方式我们应该怎么选？在选择之前我们需要搞清楚每种持久化方式的区别以及各自的优劣势。

## RDB持久化

RDB(Redis Database)

把当前内存数据生成**快照保存到硬盘**的过程，触发RDB持久化过程分为**手动触发**和**自动触发**。

（1）手动触发**save**

手动触发对应save命令，且**同步**，会阻塞当前Redis服务器，直到RDB过程完成为止，对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用。

（2）自动触发**bgsave**

自动触发对应bgsave命令，Redis进程执行**fork操作创建子进程**，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。

在redis.conf配置文件中可以配置：

```plain
save <seconds> <changes>
```
**表示xx秒内数据修改xx次时自动触发bgsave**。

如果想关闭自动触发，可以在save命令后面加一个空串，即：

```plain
save ""
```
还有其他常见可以触发bgsave，如：
* 如果从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送给从节点。
* 默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则自动执行bgsave。

### 备份的过程

Redis 会单独创建(fork)一个子进程来进行持久化，会先将数据写入到**一个临时文件**中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 

整个过程中，主进程是不进行任何 IO 操作的，这就确保了极高的性能。

### Fork

Fork 的作用是复制一个与当前进程一样的进程。新进程的所有数据(变量、环境变量、 程序计数器等) 数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程

该过程叫做**写时复制技术**

### bgsave工作机制

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204242002261.png" width="400"/>

 

（1）执行bgsave命令，Redis父进程判断当前是否存在正在执行的子进程，如RDB/AOF子进程，如果存在，bgsave命令直接返回。

（2）父进程执行fork操作创建子进程，fork操作过程中父进程会阻塞，通过info stats命令查看latest_fork_usec选项，可以获取最近一个fork操作的耗时，单位为微秒

（3）父进程fork完成后，bgsave命令返回 “Background saving started” 信息并不再阻塞父进程，可以继续响应其他命令。

（4）子进程创建RDB文件（**dump.rdb**），根据父进程内存生成临时快照文件，完成后对原有文件进行原子替换。执行lastsave命令可以获取最后一次生成RDB的 时间，对应info统计的rdb_last_save_time选项。

（5）进程发送信号给父进程表示完成，父进程更新统计信息，具体见 info Persistence下的rdb_*相关选项。

### RDB的优点

- **适合大规模的数据恢复**

- **节省磁盘空间**，恢复速度快

- 性能最大化，让子线程进行写操作，主线程继续处理命令
- 容灾性好，方便备份

### RDB的缺点

- 写时复制，会需要两倍的**内存空间**

- 如果数据庞大时，fork子线程会导致服务器停止几百毫秒

- **数据安全性低**：在备份周期在一定间隔时间做一次备份，所以如果 Redis 意外 down 掉的话， 就会丢失最后一次快照后的所有修改。



## AOF持久化

AOF（append only file）

以独立**日志**的方式**记录**每次**写命令**， 重启时再重新执行AOF文件中的命令达到恢复数据的目的。只许追加文件，不可以改写文件。

AOF的主要作用是解决了数据持久化的**实时性**，目前已经是Redis持久化的主流方式。

### AOF持久化工作机制

- 开启AOF功能需要配置：appendonly yes，默认不开启。

- AOF文件名：通过appendfilename配置设置，默认文件名是appendonly.aof。

- 保存路径：同 RDB 持久化方式一致，通过dir配置指定。

AOF的工作流程操作：命令写入 （append）、文件同步（sync）、文件重写（rewrite）、重启加载 （load）。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204232121992.png" width="200"/>

（1）所有的写命令会追加到aof_buf（缓冲区）中。

（2）AOF缓冲区根据对应的持久化策略 [always, everysec, no] 向硬盘做同步操作。

- **always**：**每步同步**，每次写指令都会立刻记入日志
- **everysec**：**每秒同步**，如果宕机，本秒的数据可能丢失
- **no**：**不主动同步**，把同步时机交给操作系统

> **AOF为什么把命令追加到aof_buf中？**
>
> Redis使用单线程响应命令，如果每次写AOF文件命令都直接追加到硬盘，那么性能完全取决于当前硬盘负载。先写入缓冲区aof_buf中，还有另一个好处，Redis可以提供多种缓冲区同步硬盘的策略，在性能和安全性方面做出平衡。

（3）AOF 文件大小超过重写策略或手动重写时，会对 AOF 文件 rewrite **重写**，压缩 AOF 文件容量;

（4）当Redis服务器重启时，可以加载AOF文件中的写操作，进行数据恢复。

> **AOF 和 RDB 同时开启，系统默认取 AOF 的数据(数据不会存在丢失)**

### AOF重写（rewrite）机制

#### 重写的目的

* **减小AOF文件占用空间**；
* 更小的AOF 文件可以**更快**地被Redis**加载恢复**。

#### AOF重写可以分为手动触发和自动触发

* 手动触发：直接调用bgrewriteaof命令。
* 自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数确定自动触发时机。

auto-aof-rewrite-min-size：表示运行AOF重写时文件最小体积，默认为64MB。

auto-aof-rewrite-percentage：设置重写的基准值，文件达到 100%时开始重写(文件是原来重写后文件的 2 倍时触发)

> 例如：文件达到 70MB 开始重写，降到 50MB，下次什么时候开始重写？100MB
>
> 系统载入时或者上次重写完毕时，Redis 会记录此时 AOF 大小，设为 base_size,
>
> 如果 Redis 的 AOF 当前大小>= base_size +base_size*100% (默认)且当前大小>=64mb(默认)的情况下，Redis 会对 AOF 进行重写。



#### 重写流程

与RDB类似

(1) bgrewriteaof 触发重写，判断是否当前有 bgsave 或 bgrewriteaof 在运行，如果有，则等待该命令结束后再继续执行。

(2) 主进程 fork 出子进程执行重写操作，保证主进程不会阻塞。

(3) 子进程遍历 redis 内存中数据到临时文件，客户端的写请求同时写入 aof_buf 缓冲区和 aof_rewrite_buf 重写缓冲区保证原 AOF 文件完整以及新 AOF 文件生成期间的新的数据修改动作不会丢失。

(4.1) 子进程写完新的 AOF 文件后，向主进程发信号，父进程更新统计信息。

(4.2) 主进程把 aof_rewrite_buf 中的数据写入到新的 AOF 文件。

(5) 使用新的 AOF 文件覆盖旧的 AOF 文件，完成 AOF 重写。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204242115894.png" alt="image-20220424211515059" style="zoom:50%;" />

> AOF文件重写后为什么会变小？
>
> （1）**旧的AOF文件含有无效的命令**，如：del key1， hdel key2等。重写只保留最终数据的写入命令。
>
> （2）**多条命令可以合并**，如lpush list a，lpush list b，lpush list c可以直接转化为lpush list a b c。

### AOF的优点

- **备份机制更稳健**，丢失数据概率更低；通过 append 模式写文件，即使中途服务器宕机也不会破坏已经存在的内容
- 刻度的日志文本，通过操作 AOF 文件，**可以处理误操作**
- 定期重写，压缩 AOF 文件的大小

### AOF的缺点

- 比 RDB 占用更多的磁盘空间
- 备份恢复速度慢
- 每次读写都同步的话，会有一定的压力
- 存在个别 bug，造成恢复不能

## Redis文件数据恢复

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204232123653.png" width="300"/>



（1）AOF持久化开启且存在AOF文件时，优先加载AOF文件。

（2）AOF关闭或者AOF文件不存在时，加载RDB文件。

（3）加载AOF/RDB文件成功后，Redis启动成功。

（4）AOF/RDB文件存在错误时，Redis启动失败并打印错误信息。



# Redis内存淘汰策略

## 什么是淘汰策略？

Redis内存淘汰策略是指当缓存内存不足时，通过淘汰旧数据处理新加入数据选择的策略。

## 如何配置最大内存？

**通过配置文件配置**

修改redis.conf配置文件

```plain
maxmemory 1024mb //设置Redis最大占用内存大小为1024M
```
注意：maxmemory默认配置为0，在64位操作系统下redis最大内存为操作系统剩余内存，在32位操作系统下redis最大内存为3GB。

**通过动态命令配置**

Redis支持运行时通过命令动态修改内存大小：

```plain
//设置Redis最大占用内存大小为200M
127.0.0.1:6379> config set maxmemory 200mb 
//获取设置的Redis能使用的最大内存大小
127.0.0.1:6379> config get maxmemory 
1) "maxmemory"
2) "209715200"
```
## 淘汰策略的分类

Redis最大占用内存用完之后，如果继续添加数据，如何处理这种情况呢？实际上Redis官方已经定义了八种策略来处理这种情况：

### noeviction

默认策略，对于写请求直接返回错误，不进行淘汰。

### allkeys-lru

lru(less recently used)，最近最少使用。从所有的key中使用近似LRU算法进行淘汰。

### volatile-lru

lru(less recently used)，最近最少使用。从设置了过期时间的key中使用近似LRU算法进行淘汰。

### allkeys-random

从所有的key中随机淘汰。

### volatile-random

从设置了过期时间的key中随机淘汰。

### volatile-ttl

ttl(time to live)，在设置了过期时间的key中根据key的过期时间进行淘汰，越早过期的越优先被淘汰。

### allkeys-lfu

lfu(Least Frequently Used)，最少使用频率。从所有的key中使用近似LFU算法进行淘汰。从Redis4.0开始支持。

### volatile-lfu

lfu(Least Frequently Used)，最少使用频率。从设置了过期时间的key中使用近似LFU算法进行淘汰。从Redis4.0开始支持。

注意：当使用volatile-lru、volatile-random、volatile-ttl这三种策略时，如果没有设置过期的key可以被淘汰，则和noeviction一样返回错误。

## LRU算法

LRU(Least Recently Used)，即最近最少使用，是一种缓存置换算法。在使用内存作为缓存的时候，缓存的大小一般是固定的。其核心思想是：如果一个数据在最近一段时间没有被用到，那么将来被使用到的可能性也很小，所以就可以被淘汰掉。

**LRU在Redis中的实现**

Redis使用的是**近似LRU算法**，它跟常规的LRU算法还不太一样。近似LRU算法通过**随机采样法淘汰数据**，每次随机出5个（默认）key，从里面淘汰掉最近最少使用的key。

可以通过maxmemory-samples参数修改采样数量， 如：maxmemory-samples 10

maxmenory-samples配置的越大，淘汰的结果越接近于严格的LRU算法，但因此耗费的CPU也很高。

Redis为了实现近似LRU算法，给每个key增加了一个额外增加了一个24bit的字段，用来存储该key最后一次被访问的时间。

**Redis3.0对近似LRU的优化**

Redis3.0对近似LRU算法进行了一些优化。新算法会维护一个**候选池**（大小为16），池中的数据根据访问时间进行排序，第一次随机选取的key都会放入池中，随后每次随机选取的key只有在访问时间小于池中最小的时间才会放入池中，直到候选池被放满。当放满后，如果有新的key需要放入，则将池中最后访问时间最大（最近被访问）的移除。

当需要淘汰的时候，则直接从池中选取最近访问时间最小（最久没被访问）的key淘汰掉就行。

## LFU算法

LFU(Least Frequently Used)，是Redis4.0新加的一种淘汰策略，它的核心思想是根据key的最近**被访问的频率**进行淘汰，**很少被访问的优先被淘汰**，被访问的多的则被留下来。

LFU算法能更好的表示一个key被访问的热度。假如你使用的是LRU算法，一个key很久没有被访问到，只刚刚是偶尔被访问了一次，那么它就被认为是热点数据，不会被淘汰，而有些key将来是很有可能被访问到的则被淘汰了。如果使用LFU算法则不会出现这种情况，因为使用一次并不会使一个key成为热点数据。

# Redis内存失效策略

Redis的key一般会设置一个过期时间，等过期之后Redis会从内存清除这些key，如何清除？一般有三种策略：定时清除、惰性清除、定时扫描清除。

## 定时清除（主动）

每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。

该策略可以立即清除过期的数据，对内存很友好，但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。

## 惰性清除（被动）

当key过期之后不会立即从内存清除，只有当访问一个key时，才会判断该key是否已过期，如果过期则清除并返回空。

该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。

## 定期扫描清除（主动）

每隔一定的时间会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。

该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。

**Redis中同时使用了惰性清除和定期扫描清除两种策略。**

所谓定期扫描清除，指的是 redis 默认每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。

> 假设 redis 里放了 10w 个 key，都设置了过期时间，你每隔几百毫秒，就检查 10w 个 key，那 redis 基本上就死了，cpu 负载会很高的，消耗在你的检查过期 key 上了。注意，这里可不是每隔 100ms 就遍历所有的设置过期时间的 key，那样就是一场性能上的灾难。实际上 redis 是每隔 100ms 随机抽取一些 key 来检查和删除的。
>
> 但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个 key 的时候，redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。
>
> 获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。但是实际上这还是有问题的，如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 redis 内存块耗尽了，咋整？答案是：走内存淘汰机制。

- **内存失效满足不了的时候，走内存淘汰机制**

# 缓存更新策略（缓存一致性）

缓存更新有三种常用策略：

* **Cache aside**：先更新DB，再删除cache
* Read/Write through
* Write behind caching
## Cache aside（旁路缓存）

Cache aside最常用的缓存策略，数据请求的过程如下：

（1）如果是数据读请求，应用首先会判断缓存是否有该数据，缓存命中直接返回数据，缓存未命中即缓存穿透到数据库，从数据库查询数据然后回写到缓存中，最后返回数据给客户端。

（2）如果是数据写请求，首先**更新数据库**，然后**从缓存中删除**该数据。

详细流程可以结合以下流程图：

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202205111703897.png" width="300"/>

仔细看上面的流程可以发现，读请求常用的套路是先更新缓存再删缓存，有些同学可能要问为什么要删缓存，先更新数据库再更新缓存行不行？先更新缓存再更新数据库行不行？这里就涉及到几个坑，下面一一解读。

## Cache aside踩坑

Cache aside策略如果用错就会遇到深坑，下面我们来逐个踩。

### 踩坑一：先更新数据库，再更新缓存

如果一个写请求来了我们先更新数据库再更新缓存，在两个并发写请求下可能会导致脏数据。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202205111704482.png" width="400"/>

请求1先更新数据库，请求2后更新数据库，预期结果是数据库中age为20，缓存中age为20，但是由于请求1比请求2后更新缓存，结果导致缓存中age为18，造成了数据库与缓存不一致，缓存中age为脏数据。

### 踩坑二：先删缓存，再更新数据库

如果写请求的处理流程是先删缓存再更新数据库，在一个读请求和一个写请求并发场景下可能会出现脏数据。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202205111706102.png" width="400"/>

流程如下：

（1）写请求删除缓存数据；

（2）读请求查询缓存未击中，紧接着查询数据库，将返回的数据回写到缓存中；

（3）写请求更新数据库。

整个流程下来发现数据库中age为20，缓存中age为18，缓存和数据库数据不一致，缓存出现了脏数据。

### 最佳实践：先更新数据库，再删除缓存

在实际的系统中针对写请求推荐这种操作，但是在理论上还是存在问题。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202205111709155.png" width="400"/>

 

流程如下：

（1）读请求先查询缓存，缓存未击中，查询数据库返回数据；

（2）写请求更新数据库，删除缓存；

（3）读请求回写缓存；

整个流程操作下来发现数据库age为20，缓存age为18，即数据库与缓存不一致，导致应用程序从缓存中读到的数据都为旧数据。

但其实上述问题发生的概率非常低，因为通常数据库更新操作比内存操作耗时多出几个数量级。如上图中最后一步回写缓存通常会在更新数据库之前完成。但是为了避免这种极端情况造成脏数据所产生的影响，我们还是要为缓存设置过期时间。

## Read/Write through

### Read through

在 Cache Aside 更新模式中，应用代码需要维护两个数据存储，一个是缓存，一个是数据库。而在 Read-Through 策略下，应用程序无需管理缓存和数据库，只需要**将数据库的同步委托给缓存提供程序 Cache Provider 即可**。所有**数据交互都是通过抽象缓存层完成**的。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202205111713860.png" width="400"/>

在进行大量读取时，Read-Through 可以减少数据源上的负载，也对缓存服务的故障具备一定的弹性。如果缓存服务挂了，则缓存提供程序仍然可以通过直接转到数据源来进行操作。

Read-Through 适用于多次请求相同数据的场景。这与 Cache-Aside 策略非常相似，但是二者还是存在一些差别，这里再次强调一下：

> * 在 Cache-Aside 中，应用程序负责从数据源中获取数据并更新到缓存。
> * 在 Read-Through 中，此逻辑通常是由独立的缓存提供程序支持。

### Write through

Write-Through 策略下，当发生数据更新(Write)时，缓存提供程序 Cache Provider 负责更新底层数据源和缓存。缓存与数据源保持一致，并且写入时始终通过抽象缓存层到达数据源。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202205111713063.png" width="500"/>

## Write behind caching

**数据更新时只更新缓存，每隔一段时间将数据刷新到数据库中**。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202205111714701.png" width="500"/>

 

优点是数据写入速度非常快，适用于频繁写的场景。

缺点是缓存和数据库非强一致性。

# 缓存异常场景

## 缓存穿透

### 什么是缓存穿透？

缓存穿透是指用户请求的**数据在缓存中不存在**即没有命中，同时**在数据库中也不存在**，导致用户每次请求该数据都要去数据库中查询一遍，然后返回空。

如果有恶意攻击者**不断请求系统中不存在的数据**，会导致短时间**大量请求落在数据库上**，造成数据库压力过大，甚至击垮数据库系统。

**不断查询不存在的数据**

### 产生的原因

- redis查询不到数据，造成一直查询数据库，而且数据库也没有
- 非正常 url 访问（大部分情况都是这个）

### 解决方案

#### （1）布隆过滤器

布隆过滤器（Bloom Filter，简称BF）是一种空间效率高的概率型数据结构。

**布隆过滤器专门用来检测集合中是否存在特定的元素。**

如果在平时我们要判断一个元素是否在一个集合中，通常会采用查找比较的方法，下面分析不同的数据结构查找效率：

* 采用线性表存储，查找时间复杂度为O(N)
* 采用平衡二叉排序树（AVL、红黑树）存储，查找时间复杂度为O(logN)
* 采用哈希表存储，考虑到哈希碰撞，整体时间复杂度也要O[log(n/m)]

当需要判断一个元素是否存在于海量数据集合中，不仅查找时间慢，还会占用大量存储空间。

##### 布隆过滤器设计思想

布隆过滤器由一个长度为**m比特的位数组**（bit array）与**k个哈希函数**（hash function）组成的数据结构。位数组初始化均为0，所有的哈希函数都可以分别把输入数据尽量均匀地散列。

当要向布隆过滤器中插入一个元素时，该元素**经过k个哈希函数计算产生k个哈希值**，以哈希值作为位数组中的**下标**，将所有k个对应的比特值由0**置为1**。

当要查询一个元素时，同样将其经过哈希函数计算产生哈希值，然后**检查对应的k个比特值**：如果位数组**有任意一个对应的比特为0**，表明该元素**一定不在集合中**；如果所有比特均为1，表明该集合有可能性在集合中。

为什么不是一定在集合中呢？

- 因为不同的元素计算的哈希值有可能一样，会出现**哈希碰撞**，导致一个不存在的元素有可能对应的比特位为1，这就是所谓“假阳性”（false positive）。相对地，“假阴性”（false negative）在BF中是绝不会出现的。

> **布隆过滤器认为不在的，一定不会在集合中；布隆过滤器认为在的，可能在也可能不在集合中。**

举个例子：下图是一个布隆过滤器，共有18个比特位，3个哈希函数。集合中三个元素x，y，z通过三个哈希函数散列到不同的比特位，并将比特位置为1。当查询元素w时，通过三个哈希函数计算，发现有一个比特位的值为0，可以肯定认为该元素不在集合中。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204251438756.png" width="500"/>

 

##### 布隆过滤器优缺点

优点：

* 节省空间：不需要存储数据本身，只需要存储数据对应hash比特位
* 时间复杂度低：插入和查找的时间复杂度都为O(k)，k为哈希函数的个数

缺点：

* **存在假阳性(误识别率)**：布隆过滤器判断存在，可能出现元素不在集合中；判断准确率取决于哈希函数的个数
* **不能删除元素**：如果一个元素被删除，但是却不能从布隆过滤器中删除，这也是造成假阳性的原因了

##### 布隆过滤器适用场景

* 爬虫系统url去重
* 垃圾邮件过滤
* 黑名单

#### （2）对空值缓存

当缓存未命中，查询数据库也为空，可以将返回的空对象写到缓存中，这样下次请求该key时直接从缓存中查询返回空对象，请求不会落到持久层数据库。

为了避免存储过多空对象，通常会给空对象设置一个过期时间。

这种方法会存在两个问题：

* 如果有大量的key穿透，缓存空对象会占用宝贵的内存空间。
* 空对象的key设置了过期时间，在这段时间可能会存在缓存和持久层数据不一致的场景。

#### （3）白名单

使用 bitmaps 类型定义一个可以访问的名单，名单 id 作为 bitmaps 的偏移量， 每次访问和 bitmap 里面的 id 进行比较，如果访问 id 不在 bitmaps 里面，进行拦截，不允许访问。

效率不高

#### （4）进行实时监控

当发现 Redis 的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务

## 缓存击穿

### 什么是缓存击穿？

缓存击穿，是指一个key非常热点，在不停的扛着大并发，**大量并发集中对这一个点进行访问**，当这个key在**失效的瞬间**，持续的**大并发**就穿破缓存，**直接请求数据库**。

key 对应的数据存在，但在 redis 中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端 DB 加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端 DB 压垮。

**某个热点数据、高并发、突然过期**

### 缓存击穿危害
数据库瞬时压力骤增，造成大量请求阻塞。

### 解决方案

#### （1）预先设置热门数据

提前加大热门数据的时长

#### （2）设置过期标志更新缓存

* 物理不过期：针对热点key不设置过期时间
* 逻辑过期：把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204251449919.png" width="500"/>

从实战看这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，对于不追求严格强一致性的系统是可以接受的。

#### （3）使用互斥锁（mutex key）

让一个线程回写缓存，其他线程等待回写缓存线程执行完，重新读缓存即可。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204251449196.png" width="500"/>

 

#### （4）实时调整

监控数据，实时调整时长

## 缓存雪崩

### 什么是缓存雪崩？

缓存雪崩是指缓存中数据**大批量过期**，而查询数据量巨大，请求直接落到数据库上，引起数据库压力过大甚至宕机。

> 和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是大批量数据都过期了，很多数据都查不到从而查数据库。

**大批量过期**

### 解决方案

#### （1）均匀过期

设置不同的过期时间，让缓存失效的时间点尽量均匀。通常可以为有效期增加随机值或者统一规划有效期。

#### （2）加互斥锁

跟缓存击穿解决思路一致，**同一时间只让一个线程构建缓存**，其他线程阻塞排队。

#### （3）设置过期标志更新缓存

跟缓存击穿解决思路一致，缓存在物理上永远不过期，用一个异步的线程更新缓存。

#### （4）多级缓存策略

> nginx缓存+redis缓存+其他缓存(ehcache等)

使用主备两层缓存：

主缓存：有效期按照经验值设置，设置为主读取的缓存，主缓存失效后从数据库加载最新值。

备份缓存：有效期长，获取锁失败时读取的缓存，主缓存更新时需要同步更新备份缓存。

## 缓存预热

### 什么是缓存预热？

缓存预热就是系统上线后，**将相关的缓存数据直接先加载到缓存系统**，这样就可以避免在用户请求的时候，先查询数据库，然后再将数据回写到缓存。

如果不进行预热， 那么 Redis 初始状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中， 对数据库造成流量的压力。

### 缓存预热的操作方法

* 数据量不大的时候，工程启动的时候进行加载缓存动作；
* 数据量大的时候，设置一个定时任务脚本，进行缓存的刷新；
* 数据量太大的时候，优先保证热点数据进行提前加载到缓存。
## 缓存降级

缓存降级是指**缓存失效或缓存服务器挂掉的情况下**，不去访问数据库，**直接返回默认数据**或**访问服务的内存数据**。

在项目实战中通常会将部分热点数据缓存到服务的内存中，这样一旦缓存出现异常，可以直接使用服务的内存数据，从而避免数据库遭受巨大压力。

降级一般是有损的操作，所以尽量减少降级对于业务的影响程度。



# Redis和Mysql如何保持数据一致

### 方案一

先更新 Mysql，在更新redis，如果更新失败，可能仍然不一致

### 方案二

先删除redis缓存数据，再更新mysql，再次查询的时候再将数据添加到缓存中，可以解决方案一段问题；

但是在高并发下性能较低，而且仍然会出现数据不一致的问题，比如，线程1删除了redis中的缓存，在更新mysql，但是此时线程2在读数据，就会把mysql的旧数据缓存到redis中。

### 方案三

延迟双删

先删除redis缓存数据，再更新mysql，延迟几百毫秒再删除redis缓存数据，这样就算在更新mysql时，有其他线程读了mysql，把老数据读到了redis中，那么也会被删除掉，从而数据保持一致。



# 分布式锁

随着业务发展的需要，原单体单机部署的系统被演化成分布式集群系统后，由于分布式系统多线程、多进程并且分布在不同机器上，这将使原单机部署情况下的并发控制锁策略失效，单纯的 Java API 并不能提供分布式锁的能力。

> 分布式锁是为了保证在分布式场景下，共享资源在同一时刻只能被同一个线程访问，或者说是用来控制分布式系统之间同步访问共享资源。

## 主流的实现方案

1. **基于关系型数据库**
	- **优点**：直接借助数据库容易理解
	- **缺点**：在使用关系型数据库实现分布式锁的过程中会出现各种问题，例如数据库单点问题和可重入问题，并且在解决过程中会使得整个方案越来越复杂
2. **基于缓存**( Redis 等)
	- **优点：**性能好，实现起来较为方便
	- **缺点**：
		- key的过期时间设置难以确定，如何设置的失效时间太短，方法没等执行完，锁就自动释放了，那么就会产生并发问题。如果设置的时间太长，其他获取锁的线程就可能要平白的多等一段时间。
		- Redis的集群部署虽然能解决单点问题，但是并不是强一致性的，锁的不够健壮
3. **基于 Zookeeper** 
	- **优点**：有效地解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题，实现起来较为简单。
	- **缺点：**性能上不如使用缓存实现分布式锁

| 方案             | 复杂度 | 性能 | 可靠性 | 学习成本 |
| ---------------- | ------ | ---- | ------ | -------- |
| 基于关系型数据库 | 低     | 低   | 低     | 低       |
| 基于Redis        | 中     | 高   | 中     | 中       |
| 基于zookeeper    | 高     | 中   | 高     | 高       |

## redis 中用 setnx 设置锁

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204251522165.png" alt="image-20220425152205908" style="zoom:50%;" />



## 优化1:设置锁的过期时间

在 set 时指定过期时间(推荐)

```
SET key value [EX seconds][PX milliseconds] [NX|XX]
```



<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204251529445.png" alt="image-20220425152907536" style="zoom:50%;" />

## 优化2: UUID 防误删

1. 客户端A获取锁成功，过期时间30秒。
2. 客户端A在某个操作上阻塞了50秒。
3. 30秒时间到了，锁自动释放了。
4. 客户端B获取到了对应同一个资源的锁。
5. 客户端A从阻塞中恢复过来，释放掉了客户端B持有的锁。

解决方案：给锁的值设置为 UUID 

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204251551755.png" alt="image-20220425155136639" style="zoom:80%;" />

## 优化3:Lua脚本实现解锁(删除锁)操作的原子性

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204251543066.png" alt="image-20220425154339324" style="zoom: 33%;" />

自动释放后，b就可以获得锁，此时a继续执行锁的删除

uuid不是不一样了吗？因为a的3(1)操作以及比较过了，此时a的3就可以直接删除了，但因为自动释放了，又因为原子性，释放后b直接获得锁，导致删除的是b的锁。

解决方法：Lua脚本

```java
 @GetMapping("testLockLua")
public void testLockLua() {
    //1 声明一个uuid ,将做为一个value 放入我们的key所对应的值中
    String uuid = UUID.randomUUID().toString();
    //2 定义一个锁：lua 脚本可以使用同一把锁，来实现删除！
    String locKey = "lock"; 

    // 3 获取锁
    Boolean lock = redisTemplate.opsForValue().setIfAbsent(locKey, uuid, 3, TimeUnit.SECONDS);

    // 第一种： lock 与过期时间中间不写任何的代码。
    // redisTemplate.expire("lock",10, TimeUnit.SECONDS);//设置过期时间
    // 如果true
    if (lock) {
        // 执行的业务逻辑开始
        // 获取缓存中的num 数据
        Object value = redisTemplate.opsForValue().get("num");
        // 如果是空直接返回
        if (StringUtils.isEmpty(value)) {
            return;
        }
        
        // 执行num++的操作
        int num = Integer.parseInt(value + "");
        redisTemplate.opsForValue().set("num", String.valueOf(++num));
        
        /*使用lua脚本来锁*/
        // 定义lua 脚本
        String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";
        // 使用redis执行lua执行
        DefaultRedisScript<Long> redisScript = new DefaultRedisScript<>();
        redisScript.setScriptText(script);
        // 设置一下返回值类型 为Long
        // 因为删除判断的时候，返回的0,给其封装为数据类型。如果不封装那么默认返回String 类型，
        // 那么返回字符串与0 会有发生错误。
        redisScript.setResultType(Long.class);
        // 第一个要是script 脚本 ，第二个需要判断的key，第三个就是key所对应的值。
        redisTemplate.execute(redisScript, Arrays.asList(locKey), uuid);
    } else {
        // 其他线程等待
        try {
            Thread.sleep(1000);
            testLockLua();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}

```



## 优化4:可重入问题

参考其他重入锁的实现，可以通过对锁进行重入计数，加锁时加 1，解锁时减 1，当计数归 0 时才能释放锁。

## 优化5:轮询

线程1获取了锁，线程2没有获取到锁，那么线程2怎么知道线程1啥时候释放了锁，进而再去获取锁呢？

- 可以通过客户端轮询的方式，就是线程2过一会就来看看是不是能获取锁了。这种方式比较消耗服务器资源，当并发量比较大时，会影响服务器的效率。
- 通过Redis的发布订阅功能，当获取锁失败时，订阅锁释放消息，获取锁成功后释放时，发送锁释放消息。

## 优化6:RedLock算法解决节点挂掉的情况

以上讨论的都是redis是单节点的情况，如果这个节点挂了，那么所有的客户端都获取不到锁了

为了**实现多节点Redis的分布式锁**，Redis的作者提出了RedLock算法。

### 为什么基于故障转移实现的Redis分布式锁还不够用？

官网中举了一个例子：

客户端A获得主服务器上的锁，然后主服务器向从服务器复制数据的过程中崩了，导致数据没有复制到从数据库中，这时会在从服务器中选出来一个升级为主服务器，但新的主服务器中并没有客户端A设置的锁。所以客户端B也可以获取到锁，违背了分布式锁的**互斥性**

这就解释为什么需要RedLock算法

### RedLock算法

> **同时向N/2+1个节点申请锁，都申请到了才证明获取锁成功。**

假设有5个完全独立的Redis服务器，多节点Redis实现的RedLock算法具体如下

- 获取当前时间戳
- 客户端尝试在5个实例中按顺序获取锁，在所有实例中使用相同的键名和随机值。当在每个实例中设置锁时，需要将锁的获取时间设置为比锁过期短很多。例如，如果锁自动释放时间为10秒，则锁的获取时间在5-50毫秒。这是为了不要过长时间等待已经关闭的Redis实例，如果一个Redis实例不可用，我们应该尽快尝试获取下一个Redis实例的锁。
- 客户端通过从当前时间中减去步骤1中获得的时间戳，计算出获取锁所需的时间。当且仅当客户端能够在大多数实例(至少3个，N/2+1)中获得锁，并且花费在获取锁的总时间小于锁的有效性时间时，该锁被认为已经获得。
- 如果获得了锁，锁真正的有效时间为锁初始设置的有效时间（过期时间）减去第三步的时间，例如，锁初始有限时间为5s，获取锁花了0.5s，则锁真正的有效时间为4.5s（忽略了时钟漂移，时间漂移指两个电脑间时间流速基本相同的情况下，两个电脑（或两个进程间）时间的差值）
- 如果客户端由于某些原因无法获得锁(要么无法锁定N/2+1个Redis实例，要么有锁的有效时间为负数)，客户端将尝试解锁所有Redis实例（即使是它认为无法锁定的Redis实例）。

### RedLock算法是异步的吗？

可以看成同步算法，虽然没有跨进程的同步时钟，但每个进程（多个电脑）的本地时间仍然大致以相同的速度流动，与锁的自动释放时间相比，误差较小，将其忽略的话，则可以看成同步算法。

### RedLock失败重试

**当客户端无法获取到锁时，应该在随机时间后重试**，并且理想的客户端应该并发地将所有命令同时发给所有Redis实例。对于已经获取锁的客户端要在完成任务后及时释放锁，这样其他客户端就不需要等锁自动过期后再获取。如果在获取锁后，在主动释放锁前无法连接到Redis实例，就只能等锁自动失效了。

### 释放锁

释放锁很简单，只要释放所有实例中的锁，不需要考虑是否释放成功（释放时会判断这个锁的value值是不是自己设置的，避免释放其他客户端设置的锁）

### RedLock的 Safety arguments

- 假设客户端可以获取到大多数Redis实例，并且所有Redis实例具有相同的key和过期时间，但不同的Redis实例的key是不同的时间设置的（获取锁的时间不可能完全一致），所以过期时间也不同，假设获取第一个Redis实例的锁的时间为T1,最后一个为T2，则客户端获得锁的最小有效时间为key的有效时间-（T2-T1）-时钟漂移。
- 为什么需要获取一半以上的Redis实例的锁才算获取到锁成功呢？因为如果获取不到一半也算成功的话会导致多个客户端同时获取到锁，违背了互斥性
- 一个客户端锁定大多数Redis实例所需的时间大于或者接近锁的过期时间时，会认为锁无效，并解锁所有Redis实例

### RedLock崩溃的相关解决方法

场景：客户端A在成功获取锁后，如果所有Redis重启，这时客户端B就可以再次获取到锁，违背了互斥性

解决方法：开启AOF持久化，可以解决这个问题，但是AOF同步到磁盘上的方式默认是每秒一次，如果1秒内断电，会导致1秒内的数据丢失，如果客户端是在这1秒内获得的锁，立即重启可能会导致锁的互斥性失效，解决方法是每次Redis无论因为什么原因停掉都要等key的过期时间到了再重启（延迟重启），这么做的缺点就是在等待重启这段时间内Redis处于关闭的状态。

<br>

## Redis并发竞争key问题应该如何解决？

Redis并发竞争key就是多个客户端操作一个key，可能会导致数据出现问题，主要有以下几种解决办法：

- **乐观锁**，`watch` 命令可以方便地实现乐观锁。`watch` 命令会监视给定的每一个key，当 `exec` 时如果监视的任一个key自从调用watch后发生过变化，则整个事务会失败，不执行任何动作。不能在分片集群中使用
- **分布式锁**，适合分布式场景
- **时间戳**，适合有序场景，比如A想把key设置为1，B想把key设置为2，C想把key设置为3，对每个操作加上时间戳，写入前先比较自己的时间戳是不是早于现有记录的时间戳，如果早于，就不写入了
- **消息队列**，串行化处理

## 总结

为了确保分布式锁可用，至少要确保锁的实现同时满足以下条件:

- **互斥性**：在任意时刻，同一条数据只能被一台机器上的一个线程执行
- **高可用性**：当部分节点宕机后，客户端仍可以正常地获取锁和释放锁
- **独占性**：加锁和解锁必须同一台服务器执行，不能在一个服务器上加锁，在另一个服务器上释放锁
- **防锁超时**（死锁）：如果客户端没有主动释放锁，服务器会在一定时间后自动释放锁， 防止客户端宕机或者网络异常导致宕机
- **原子性**：加锁和解锁必须具有原子性

# 高可用架构

1. 主从复制：主库可以读写，并且会**和从库进行数据同步**，这种模式下，客户端直接连主库或某个从库，但是当主库或从库容机后，客户端需要手动修改IP，另外，这种模式也比较难进行扩容，整个集群所能存储的数据受到某台机器的内存容量，所以**不能支持特大数据量**。
2. 哨兵模式：这种模式在主从的基础上新增了哨兵节点，但主库节点**宕机后**，**哨兵**会发现主库节点宕机，然后**在从库中选择一个库作为新的主库**，另外哨兵也可以做集群，从而可以保证当某一个哨兵节点容机后，还有其他哨兵节点可以继续工作，这种模式可以比较好的保证Redis集群的**高可用**，但是仍然**不能**很好的解决Redis的**容量上限问题**。
3. Cluster模式：支持**多主多从**，这种模式会按照key进行槽位的分配，可以使得不同的key分散到不同的主节点上，利用这种模式可以使得整个集群**支持更大的数据容量**，同时每个主节点可以拥有自己的多个从节点，如果该主节点宕机，会从它的从节点中选举一个新的主节点。

## Replication（主从复制）

### 什么是主从复制？

主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。

**master 以写为主，slave 以读为主**，主库会和从库进行数据同步。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204242123054.png" alt="image-20220424212334512" style="zoom:50%;" />

### 主从复制的作用

1. **数据冗余**：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。
2. **故障恢复**：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。
3. **负载均衡**：在主从复制的基础上，配合**读写分离**，可以由主节点提供写服务，由从节点提供读服务，分担服务器负载；尤其是在**写少读多**的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。
4. **高可用基石**：主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。



### 使用方法

见pdf

- 一主二仆

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204242219106.png" alt="image-20220424221934993" style="zoom:50%;" />

主机挂掉，重启即可，从机还是其从机

从机挂掉需要重新 slaveof，并且会从头复制数据

- 薪火相传

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204242218660.png" alt="image-20220424221800702" style="zoom:50%;" />

上一个 Slave 可以是下一个 slave 的 Master

中途变更转向：会清除之前的数据，重新建立拷贝最新的 

风险是一旦某个 slave 宕机，后面的 slave 都没法备份

主机挂了，从机还是从机，但是无法写数据了

- **反客为主**

**当一个 master 宕机后，后面的 slave 可以立刻升为 master**，其后面的 slave 不用做任何修改。

用 slaveof no one 将从机变为主机。

### 主从复制实现原理

主从复制过程主要可以分为3个阶段：连接建立阶段、数据同步阶段、命令传播阶段。

#### 连接建立阶段

1、集群启动时，master 会先建立连接，为全量复制做准备。

#### 数据同步阶段***

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204242214035.png" alt="03-主从复制原理" style="zoom:75%;" />

主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。具体执行的方式是：从节点向主节点发送psync命令（Redis2.8以前是sync命令），开始同步。

**数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和增量复制。**

2、Master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令， 在后台进程执行完毕之后，master 将传送整个数据文件RDB到 slave，同时在写rdb文件的时候，也在内存中用专门的 replication buffer，**记录**写rdb期间的请求传进来的**写操作**；

3、而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中（**全量复制**）；Master 继续将上一过程中新的收集到的修改命令依次传给 slave，完成同步（**增量复制**）

#### 命令传播阶段

数据同步阶段完成后，主从节点进入命令传播阶段；

4、master 将自己执行的写命令发送给从节点，slave 接收命令并执行，从而保证主从节点数据的一致性。

命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复。

<br>

## Sentinel（哨兵模式）

Redis 的主从复制模式下，一旦主节点由于故障不能提供服务，需要**手动**将从节点晋升为主节点，同时还要通知客户端更新主节点 ip 地址。

Redis 2.8 以后提供了 Redis Sentinel 哨兵机制来解决这个问题。

“反客为主的**自动版**”

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204242226447.png" alt="image-20220424222615034" style="zoom:50%;" />

### 什么是哨兵模式？

Redis Sentinel 是 Redis 高可用的实现方案。Sentinel 是一个管理多个 Redis 实例的工具，它可以实现对 Redis 的监控、通知、自动故障转移。

Redis Sentinel架构图如下：

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204242127151.png" width="500"/>

### 配置方式

见pdf

`sentinel monitor mymaster 127.0.0.1 6379 1`

- 其中 mymaster 为监控对象起的服务器名称， 

- 1 为至少有多少个哨兵同意迁移的数量；**设置多个哨兵后可以降低哨兵误判的几率**

### 复制延时

由于所有的写操作都是先在 Master 上操作，然后同步更新到 Slave 上，所以从 Master 同步到 Slave 机器有一定的延迟，

当系统很繁忙的时候，延迟问题会更加严重，Slave 机器数量的增加也会使这个问题更加严重。

### 故障恢复

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204242241592.png" alt="image-20220424224133011" style="zoom:50%;" />

优先级在 redis.conf 中默认：replica-priority 100，值越小优先级越高（0永远不会被选为主机）

**偏移量是指获得原主机数据的数量**

每个 redis 实例启动后都会随机生成一个 40 位的 runid



### 哨兵模式的原理

哨兵模式的主要作用在于它能够**自动**完成**故障发现**和**故障转移**，并通知客户端，从而实现高可用。哨兵模式通常由一组 Sentinel 节点和一组（或多组）主从复制节点组成。

#### 心跳机制

（1）Sentinel与Redis Node

Redis Sentinel 是一个特殊的 Redis 节点。在哨兵模式创建时，需要通过配置指定 Sentinel 与 Redis Master Node 之间的关系，然后 Sentinel 会从主节点上获取所有从节点的信息，之后 Sentinel 会定时向主节点和从节点发送 info 命令获取其拓扑结构和状态信息。

（2）Sentinel与Sentinel

基于 Redis 的订阅发布功能， 每个 Sentinel 节点会向主节点的 __sentinel__：hello 频道上发送该 Sentinel 节点对于主节点的判断以及当前 Sentinel 节点的信息 ，同时每个 Sentinel 节点也会订阅该频道， 来获取其他 Sentinel 节点的信息以及它们对主节点的判断。

通过以上两步所有的 Sentinel 节点以及它们与所有的 Redis 节点之间都已经彼此感知到，之后每个 Sentinel 节点会向主节点、从节点、以及其余 Sentinel 节点定时发送 ping 命令作为心跳检测， 来确认这些节点是否可达。

#### 故障转移

每个 Sentinel 都会定时进行心跳检查，当发现主节点出现心跳检测超时的情况时，此时认为该主节点已经不可用，这种判定称为**主观下线**。

之后该 Sentinel 节点会通过 sentinel ismaster-down-by-addr 命令向其他 Sentinel 节点询问对主节点的判断， **当 quorum（法定人数） 个 Sentinel 节点都认为该节点故障时**，则执行**客观下线**，即认为该节点已经不可用。这也同时解释了为什么必须需要一组 Sentinel 节点，因为单个 Sentinel 节点很容易对故障状态做出误判。

>这里 quorum 的值是我们在哨兵模式搭建时指定的，后文会有说明，通常为 **Sentinel节点总数/2+1**，即**半数以上节点做出主观下线判断就可以执行客观下线**。

因为**故障转移的工作只需要一个 Sentinel 节点来完成**，所以 Sentinel 节点之间会再做一次选举工作， 基于 Raft 算法选出一个 Sentinel 领导者来进行故障转移的工作。

被选举出的 Sentinel 领导者进行故障转移的具体步骤如下：

（1）在从节点列表中选出一个节点作为新的主节点

* 过滤不健康或者不满足要求的节点；
* 选择 slave-priority（优先级）最高的从节点， 如果存在则返回， 不存在则继续；
* 选择复制偏移量最大的从节点 ， 如果存在则返回， 不存在则继续；
* 选择 runid 最小的从节点。

（2）对选出来的从节点执行 slaveof no one 命令让其成为主节点。

（3）向剩余的从节点发送命令，让他们从新的主节点上复制数据。

（4）将原来的主节点更新为从节点， 并对其进行监控， 当其恢复后命令它去复制新的主节点。

<br>

## Cluster（集群）

### 为什么要引入Cluster模式？

容量不够，redis 如何进行扩容? 

并发写操作， redis 如何分摊?

另外，主从模式，薪火相传模式，主机宕机，导致 ip 地址发生变化，应用程序中配置需要修改对应的主机地址、端口等信息。

之前通过代理主机来解决，但是 redis3.0 中提供了解决方案。就是无中心化集群配置。

> 不管是主从模式还是哨兵模式都只能由一个master在写数据，在海量数据高并发场景，一个节点写数据容易出现瓶颈，**引入Cluster模式可以实现多个节点同时写数据**。

### 什么是Cluster模式？

Redis-Cluster采用无中心结构，每个节点都保存数据，节点之间互相连接从而知道整个集群状态。

<img src="https://cdn.jsdelivr.net/gh/YiENx1205/cloudimgs/notes/202204242127462.png" width="500"/>

如图所示Cluster模式其实就是**多个主从复制的结构组合**起来的，每一个主从复制结构可以看成一个节点，那么上面的Cluster集群中就有三个节点。

- Redis 集群实现了对 Redis 的水平扩容，即启动 N 个 redis 节点，将整个数据库分布存 储在这 N 个节点中，每个节点存储总数据的 1/N。

- Redis 集群通过分区(partition)来提供一定程度的可用性(availability): 即使集群 中有一部分节点失效或者无法进行通讯， 集群也可以继续处理命令请求。

**任何一个节点都可以作为集群入口**

### 节点分配原则

分配原则尽量保证每个主数据库运行在不同的 IP 地址，每个从库和主库不在一个 IP 地址上。

即每个库都在不同的服务器上

### slots槽

举例，三个主机，三个从机，三组

```
[OK] All 16384 slots covered
```

一个 Redis 集群包含 16384 (2^14) 个插槽(hash slot)， 数据库中的每个键都属于这 16384 个插槽的其中一个。（类似 hashcode）

集群使用公式 `CRC16(key) % 16384` 来计算键 key 属于哪个槽， 其中 `CRC16(key)` 语句用于计算键 key 的 CRC16 校验和 。

集群中的每个节点负责处理一部分插槽。 举个例子， 如果一个集群可以有主节点， 其中:

- 节点 A 负责处理 0 号至 5460 号插槽。

- 节点 B 负责处理 5461 号至 10922 号插槽。 

- 节点 C 负责处理 10923 号至 16383 号插槽。

> 目的：分配数据

### 集群中录入值

redis-cli 客户端提供了 –c 参数实现自动重定向。

如 redis-cli -c –p 6379 登入后，再录入、查询键值对可以自动重定向。

比如：在6379中录入，但是计算插槽后不属于6379，这时候需要重定向。

不在一个 slot 下的键值，是不能使用 mget,mset 等多键操作。

可以通过{}来定义组的概念，从而使 key 中{}内相同内容的键值对放到一个 slot 中去。

```
mset name{user} lucy age{user} 20
```



### Cluster模式的原理

#### Redis集群TCP端口

每个Redis集群节点都需要开启两个TCP监听端口，一个用于给客户端提供普通的Redis服务，常见为6379，另外一个用于集群间通信服务，一般为在普通端口基础上偏移10000如16379。

第二个端口用于集群总线，即使用二进制协议的节点到节点的通信通道。节点使用集群总线进行**故障检测**，**配置更新**，**故障转移授权**等。客户端永远不应尝试与集群总线端口通信，但始终使用正常的Redis命令端口，但请确保在防火墙中打开两个端口，否则Redis集群节点将无法通信。

#### Redis集群数据分片

见slots

### 优点

实现扩容、分摊压力、无中心配置相对简单

### 缺点

多键操作是不被支持的

多键的 Redis 事务是不被支持的。

**lua 脚本不被支持**

由于集群方案出现较晚，很多公司已经采用了其他的集群方案，而代理或者客户端分片的方案想要迁移至 redis cluster，需要整体迁移而不是逐步过渡，复杂度较大。

# 实战篇

## Java应用

[应用](https://blog.csdn.net/whatfuswd/article/details/121806023?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-121806023-null-null.pc_agg_new_rank&utm_term=redis%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96java%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0&spm=1000.2123.3001.4430)
